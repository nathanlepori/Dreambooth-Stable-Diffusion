{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa2c1ada",
   "metadata": {
    "id": "aa2c1ada"
   },
   "source": [
    "# Dreambooth\n",
    "### Notebook implementation by Joe Penna (@MysteryGuitarM on Twitter) - Improvements by David Bielejeski\n",
    "\n",
    "### Instructions\n",
    "- Sign up for RunPod here: https://runpod.io/?ref=n8yfwyum\n",
    "    - Note: That's my personal referral link. Please don't use it if we are mortal enemies.\n",
    "\n",
    "- Click *Deploy* on either `SECURE CLOUD` or `COMMUNITY CLOUD`\n",
    "\n",
    "- Follow the rest of the instructions in this video: https://www.youtube.com/watch?v=7m__xadX0z0#t=5m33.1s\n",
    "\n",
    "Latest information on:\n",
    "https://github.com/JoePenna/Dreambooth-Stable-Diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b971cc0",
   "metadata": {
    "id": "7b971cc0"
   },
   "source": [
    "## Build Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e1bc458-091b-42f4-a125-c3f0df20f29d",
   "metadata": {
    "id": "9e1bc458-091b-42f4-a125-c3f0df20f29d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: omegaconf in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from omegaconf) (6.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from omegaconf) (4.9.3)\n",
      "Requirement already satisfied: einops in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: pytorch-lightning==1.6.5 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.6.5)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytorch-lightning==1.6.5) (4.3.0)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytorch-lightning==1.6.5) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.17.2 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytorch-lightning==1.6.5) (1.23.4)\n",
      "Requirement already satisfied: protobuf<=3.20.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytorch-lightning==1.6.5) (3.19.6)\n",
      "Requirement already satisfied: PyYAML>=5.4 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytorch-lightning==1.6.5) (6.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytorch-lightning==1.6.5) (21.3)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytorch-lightning==1.6.5) (2022.8.2)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytorch-lightning==1.6.5) (2.9.1)\n",
      "Requirement already satisfied: pyDeprecate>=0.3.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytorch-lightning==1.6.5) (0.3.2)\n",
      "Requirement already satisfied: torch>=1.8.* in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytorch-lightning==1.6.5) (1.13.0)\n",
      "Requirement already satisfied: torchmetrics>=0.4.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytorch-lightning==1.6.5) (0.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (2.28.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (3.8.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=17.0->pytorch-lightning==1.6.5) (3.0.9)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (2.1.2)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (1.47.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (0.4.6)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (1.1.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (2.9.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (3.3.7)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (59.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.57.0->pytorch-lightning==1.6.5) (0.4.4)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (2.0.12)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (1.8.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (4.0.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.5) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.5) (4.8)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.5) (1.16.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.5) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.5) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (3.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.5) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.5) (3.2.0)\n",
      "Requirement already satisfied: test-tube in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.7.5)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from test-tube) (1.23.4)\n",
      "Requirement already satisfied: pandas>=0.20.3 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from test-tube) (1.4.2)\n",
      "Requirement already satisfied: imageio>=2.3.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from test-tube) (2.22.0)\n",
      "Requirement already satisfied: tensorboard>=1.15.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from test-tube) (2.9.1)\n",
      "Requirement already satisfied: future in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from test-tube) (0.18.2)\n",
      "Requirement already satisfied: torch>=1.1.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from test-tube) (1.13.0)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imageio>=2.3.0->test-tube) (9.0.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.20.3->test-tube) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.20.3->test-tube) (2.8.2)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=1.15.0->test-tube) (1.47.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=1.15.0->test-tube) (3.19.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=1.15.0->test-tube) (3.3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=1.15.0->test-tube) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=1.15.0->test-tube) (2.1.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=1.15.0->test-tube) (2.28.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=1.15.0->test-tube) (59.5.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=1.15.0->test-tube) (0.37.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=1.15.0->test-tube) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=1.15.0->test-tube) (1.8.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=1.15.0->test-tube) (1.1.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=1.15.0->test-tube) (2.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.1.0->test-tube) (4.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15.0->test-tube) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15.0->test-tube) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15.0->test-tube) (1.16.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15.0->test-tube) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.15.0->test-tube) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=1.15.0->test-tube) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=1.15.0->test-tube) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=1.15.0->test-tube) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=1.15.0->test-tube) (2022.6.15)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.15.0->test-tube) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.15.0->test-tube) (3.2.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.22.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2022.9.13)\n",
      "Requirement already satisfied: filelock in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.23.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.28.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: kornia in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.6.7)\n",
      "Requirement already satisfied: torch>=1.8.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kornia) (1.13.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kornia) (21.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.1->kornia) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->kornia) (3.0.9)\n",
      "Obtaining taming-transformers from git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers\n",
      "  Updating c:\\users\\natha\\documents\\altri progetti\\dreambooth-stable-diffusion\\src\\taming-transformers clone (to revision master)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: torch in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from taming-transformers) (1.13.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from taming-transformers) (1.23.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from taming-transformers) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch->taming-transformers) (4.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->taming-transformers) (0.4.4)\n",
      "Installing collected packages: taming-transformers\n",
      "  Attempting uninstall: taming-transformers\n",
      "    Found existing installation: taming-transformers 0.0.1\n",
      "    Uninstalling taming-transformers-0.0.1:\n",
      "      Successfully uninstalled taming-transformers-0.0.1\n",
      "  Running setup.py develop for taming-transformers\n",
      "Successfully installed taming-transformers-0.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git fetch -q --tags\n",
      "  Running command git reset --hard -q 24268930bf1dce879235a7fddd0b2355b84d7ea6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining clip from git+https://github.com/openai/CLIP.git@main#egg=clip\n",
      "  Updating c:\\users\\natha\\documents\\altri progetti\\dreambooth-stable-diffusion\\src\\clip clone (to revision main)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: ftfy in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from clip) (6.1.1)\n",
      "Requirement already satisfied: regex in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from clip) (2022.9.13)\n",
      "Requirement already satisfied: tqdm in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from clip) (4.64.1)\n",
      "Requirement already satisfied: torch in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from clip) (1.13.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from clip) (0.14.0)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ftfy->clip) (0.2.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch->clip) (4.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision->clip) (2.28.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision->clip) (9.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision->clip) (1.23.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->clip) (0.4.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision->clip) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision->clip) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision->clip) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision->clip) (1.26.9)\n",
      "Installing collected packages: clip\n",
      "  Attempting uninstall: clip\n",
      "    Found existing installation: clip 1.0\n",
      "    Uninstalling clip-1.0:\n",
      "      Successfully uninstalled clip-1.0\n",
      "  Running setup.py develop for clip\n",
      "Successfully installed clip-1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git fetch -q --tags\n",
      "  Running command git reset --hard -q d50d76daa670286dd6cacf3bcd80b5e4823fc8e1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools==59.5.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (59.5.0)\n",
      "Requirement already satisfied: pillow==9.0.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (9.0.1)\n",
      "Requirement already satisfied: torchmetrics==0.6.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchmetrics==0.6.0) (21.3)\n",
      "Requirement already satisfied: torch>=1.3.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchmetrics==0.6.0) (1.13.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchmetrics==0.6.0) (1.23.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.3.1->torchmetrics==0.6.0) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->torchmetrics==0.6.0) (3.0.9)\n",
      "Obtaining file:///C:/Users/natha/Documents/Altri%20progetti/Dreambooth-Stable-Diffusion\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: torch in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from latent-diffusion==0.0.1) (1.13.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from latent-diffusion==0.0.1) (1.23.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from latent-diffusion==0.0.1) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch->latent-diffusion==0.0.1) (4.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->latent-diffusion==0.0.1) (0.4.4)\n",
      "Installing collected packages: latent-diffusion\n",
      "  Attempting uninstall: latent-diffusion\n",
      "    Found existing installation: latent-diffusion 0.0.1\n",
      "    Uninstalling latent-diffusion-0.0.1:\n",
      "      Successfully uninstalled latent-diffusion-0.0.1\n",
      "  Running setup.py develop for latent-diffusion\n",
      "Successfully installed latent-diffusion-0.0.1\n",
      "Collecting protobuf==3.20.1\n",
      "  Using cached protobuf-3.20.1-cp310-cp310-win_amd64.whl (903 kB)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "Successfully installed protobuf-3.20.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.1 which is incompatible.\n",
      "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.1 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.5.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gdown) (4.64.1)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gdown) (2.28.0)\n",
      "Requirement already satisfied: six in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gdown) (4.11.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gdown) (3.8.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests[socks]->gdown) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests[socks]->gdown) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests[socks]->gdown) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests[socks]->gdown) (2.0.12)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->gdown) (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-api-core 2.10.1 requires protobuf<5.0.0dev,>=3.20.1, but you have protobuf 3.19.6 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface_hub) (6.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface_hub) (4.64.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface_hub) (3.8.0)\n",
      "Requirement already satisfied: requests in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface_hub) (2.28.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface_hub) (4.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface_hub) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=20.9->huggingface_hub) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface_hub) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface_hub) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface_hub) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface_hub) (1.26.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->huggingface_hub) (0.4.4)\n",
      "Requirement already satisfied: ipywidgets==7.7.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (7.7.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipywidgets==7.7.1) (1.1.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipywidgets==7.7.1) (5.3.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipywidgets==7.7.1) (6.15.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipywidgets==7.7.1) (0.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipywidgets==7.7.1) (3.6.1)\n",
      "Requirement already satisfied: ipython>=4.0.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipywidgets==7.7.1) (8.4.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets==7.7.1) (0.1.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets==7.7.1) (21.3)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets==7.7.1) (7.3.4)\n",
      "Requirement already satisfied: debugpy>=1.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets==7.7.1) (1.6.0)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets==7.7.1) (1.5.5)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets==7.7.1) (6.1)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets==7.7.1) (23.1.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets==7.7.1) (5.9.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=4.0.0->ipywidgets==7.7.1) (0.18.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=4.0.0->ipywidgets==7.7.1) (59.5.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=4.0.0->ipywidgets==7.7.1) (5.1.1)\n",
      "Requirement already satisfied: backcall in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=4.0.0->ipywidgets==7.7.1) (0.2.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=4.0.0->ipywidgets==7.7.1) (0.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=4.0.0->ipywidgets==7.7.1) (0.4.4)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=4.0.0->ipywidgets==7.7.1) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=4.0.0->ipywidgets==7.7.1) (3.0.28)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=4.0.0->ipywidgets==7.7.1) (2.11.2)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (6.4.12)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets==7.7.1) (0.8.3)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets==7.7.1) (0.4)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets==7.7.1) (4.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets==7.7.1) (2.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (0.15.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (1.8.0)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (21.3.0)\n",
      "Requirement already satisfied: nbformat in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (5.4.0)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (0.14.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (3.1.2)\n",
      "Requirement already satisfied: nbconvert>=5 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (6.5.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets==7.7.1) (0.2.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->ipykernel>=4.5.1->ipywidgets==7.7.1) (3.0.9)\n",
      "Requirement already satisfied: asttokens in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets==7.7.1) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets==7.7.1) (0.2.2)\n",
      "Requirement already satisfied: executing in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets==7.7.1) (0.8.3)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets==7.7.1) (304)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (1.5.0)\n",
      "Requirement already satisfied: bleach in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (5.0.0)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (1.1.1)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (0.7.1)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (0.6.4)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (4.11.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (0.2.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (0.8.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (2.1.1)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (2.15.3)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (4.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets==7.7.1) (1.16.0)\n",
      "Requirement already satisfied: pywinpty>=1.1.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (2.0.5)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (21.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (0.18.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (21.4.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (1.15.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (2.3.2.post1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (0.5.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (2.21)\n",
      "Requirement already satisfied: captionizer==1.0.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "# BUILD ENV\n",
    "!pip install omegaconf\n",
    "!pip install einops\n",
    "!pip install pytorch-lightning==1.6.5\n",
    "!pip install test-tube\n",
    "!pip install transformers\n",
    "!pip install kornia\n",
    "!pip install -e git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers\n",
    "!pip install -e git+https://github.com/openai/CLIP.git@main#egg=clip\n",
    "!pip install setuptools==59.5.0\n",
    "!pip install pillow==9.0.1\n",
    "!pip install torchmetrics==0.6.0\n",
    "!pip install -e .\n",
    "!pip install protobuf==3.20.1\n",
    "!pip install gdown\n",
    "!pip install -qq diffusers[\"training\"]==0.3.0 transformers ftfy\n",
    "!pip install -qq \"ipywidgets>=7,<8\"\n",
    "!pip install huggingface_hub\n",
    "!pip install ipywidgets==7.7.1\n",
    "!pip install captionizer==1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a2ef29b-c76c-4b63-bfd8-1f9f4d6f2283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu117\n",
      "Requirement already satisfied: torch in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.13.0+cu117)\n",
      "Requirement already satisfied: torchvision in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.14.0+cu117)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.13.0+cu117)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (1.23.4)\n",
      "Requirement already satisfied: requests in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (2.28.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\natha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (2022.6.15)\n"
     ]
    }
   ],
   "source": [
    "# Various fixes\n",
    "import platform\n",
    "\n",
    "if platform.system() == \"Linux\":\n",
    "    # Possible fix for older CUDA version?\n",
    "    !pip install -U torch==1.12.0 torchvision==0.13.0 torchtext==0.13.0\n",
    "elif platform.system() == \"Windows\":\n",
    "    # Fix no support for CUDA on Win by default (newish GPUs)\n",
    "    !pip install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "943b48a6-e701-49e6-9af0-84770f19fe82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch==1.13.0+cpu\n",
      "pytorch_lightning==1.6.5\n",
      "torchvision==0.14.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import torchvision\n",
    "\n",
    "print(\"torch==\" + torch.__version__)\n",
    "print(\"pytorch_lightning==\" + pl.__version__)\n",
    "print(\"torchvision==\" + torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae11c10",
   "metadata": {
    "id": "dae11c10"
   },
   "outputs": [],
   "source": [
    "# Hugging Face Login\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e165700",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Download the 1.4 sd model\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "downloaded_model_path = hf_hub_download(\n",
    " repo_id=\"CompVis/stable-diffusion-v-1-4-original\",\n",
    " filename=\"sd-v1-4.ckpt\",\n",
    " use_auth_token=True\n",
    ")\n",
    "\n",
    "# Move the sd-v1-4.ckpt to the root of this directory as \"model.ckpt\"\n",
    "actual_locations_of_model_blob = !readlink -f {downloaded_model_path}\n",
    "!mv {actual_locations_of_model_blob[-1]} model.ckpt\n",
    "clear_output()\n",
    "print(\" model.ckpt successfully downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e3be50-8dce-41ee-96f2-4e5d7f656fc8",
   "metadata": {},
   "source": [
    "# Fixed version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "709c5aa4-6c89-4e14-8dc0-403c08e794af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /opt/conda/lib/python3.9/site-packages (4.5.3)\n",
      "Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.9/site-packages (from gdown) (2.27.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from gdown) (3.6.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.9/site-packages (from gdown) (4.11.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from gdown) (4.63.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.9/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests[socks]->gdown) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests[socks]->gdown) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests[socks]->gdown) (3.3)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.9/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1SjqfFU3G9JXbHHS-8dQI-QfntNtZY7sS\n",
      "To: /workspace/Dreambooth-Stable-Diffusion/sd-v1-4.ckpt\n",
      "100%|| 4.27G/4.27G [02:52<00:00, 24.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "%pip install gdown\n",
    "\n",
    "!gdown https://drive.google.com/uc?id=1SjqfFU3G9JXbHHS-8dQI-QfntNtZY7sS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d1d11a",
   "metadata": {
    "id": "17d1d11a"
   },
   "source": [
    "# Regularization Images (Skip this section if you are uploading your own or using the provided images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed07a5df",
   "metadata": {
    "id": "ed07a5df"
   },
   "source": [
    "Training teaches your new model both your token **but** re-trains your class simultaneously.\n",
    "\n",
    "From cursory testing, it does not seem like reg images affect the model too much. However, they do affect your class greatly, which will in turn affect your generations.\n",
    "\n",
    "You can either generate your images here, or use the repos below to quickly download 1500 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f9ff0c-b529-4c7c-8e26-8388d70a5d91",
   "metadata": {
    "id": "67f9ff0c-b529-4c7c-8e26-8388d70a5d91"
   },
   "outputs": [],
   "source": [
    "# GENERATE 200 images - Optional\n",
    "self_generated_files_prompt = \"person\" #@param {type:\"string\"}\n",
    "self_generated_files_count = 200 #@param {type:\"integer\"}\n",
    "\n",
    "!python scripts/stable_txt2img.py \\\n",
    " --seed 10 \\\n",
    " --ddim_eta 0.0 \\\n",
    " --n_samples 1 \\\n",
    " --n_iter {self_generated_files_count} \\\n",
    " --scale 10.0 \\\n",
    " --ddim_steps 50 \\\n",
    " --ckpt model.ckpt \\\n",
    " --prompt {self_generated_files_prompt}\n",
    "\n",
    "dataset=self_generated_files_prompt\n",
    "\n",
    "!mkdir -p regularization_images/{dataset}\n",
    "!mv outputs/txt2img-samples/*.png regularization_images/{dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1c7e1c",
   "metadata": {
    "id": "3d1c7e1c"
   },
   "outputs": [],
   "source": [
    "# Zip up the files for downloading and reuse.\n",
    "# Download this file locally so you can reuse during another training on this dataset\n",
    "!apt-get install -y zip\n",
    "!zip -r regularization_images.zip regularization_images/{dataset}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc41609f",
   "metadata": {},
   "source": [
    "# Download pre-generated regularization images\n",
    "We've created the following image sets\n",
    "\n",
    "`man_euler` - provided by Niko Pueringer (Corridor Digital) - euler @ 40 steps, CFG 7.5\n",
    "`man_unsplash` - pictures from various photographers\n",
    "`person_ddim`\n",
    "`woman_ddim` - provided by David Bielejeski - ddim @ 50 steps, CFG 10.0\n",
    "`person_ddim` is recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7EydXCjOV1v",
   "metadata": {
    "id": "e7EydXCjOV1v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Stable-Diffusion-Regularization-Images-woman_ddim' already exists and is not an empty directory.\n",
      "mv: cannot stat 'Stable-Diffusion-Regularization-Images-woman_ddim/woman_ddim/*.*': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "#Download Regularization Images\n",
    "\n",
    "dataset=\"woman_ddim\" #@param [\"man_euler\", \"man_unsplash\", \"person_ddim\", \"woman_ddim\", \"blonde_woman\"]\n",
    "!git clone https://github.com/djbielejeski/Stable-Diffusion-Regularization-Images-{dataset}.git\n",
    "\n",
    "!mkdir -p regularization_images/{dataset}\n",
    "!mv -v Stable-Diffusion-Regularization-Images-{dataset}/{dataset}/*.* regularization_images/{dataset}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319536de",
   "metadata": {},
   "source": [
    "# Upload your training images\n",
    "Upload 10-20 images of someone to\n",
    "\n",
    "```\n",
    "/workspace/Dreambooth-Stable-Diffusion/training_images\n",
    "```\n",
    "\n",
    "WARNING: Be sure to upload an *even* amount of images, otherwise the training inexplicably stops at 1500 steps.\n",
    "\n",
    "*   2-3 full body\n",
    "*   3-5 upper body\n",
    "*   5-12 close-up on face\n",
    "\n",
    "The images should be:\n",
    "\n",
    "- as close as possible to the kind of images you're trying to make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb9ca53",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#@markdown Add here the URLs to the images of the subject you are adding\n",
    "urls = [\n",
    " \"https://i.imgur.com/test1.png\",\n",
    " \"https://i.imgur.com/test2.png\",\n",
    " \"https://i.imgur.com/test3.png\",\n",
    " \"https://i.imgur.com/test4.png\",\n",
    " \"https://i.imgur.com/test5.png\",\n",
    " # You can add additional images here -- about 20-30 images in different\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b6f513",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#@title Download and check the images you have just added\n",
    "import os\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def image_grid(imgs, rows, cols):\n",
    " assert len(imgs) == rows*cols\n",
    "\n",
    " w, h = imgs[0].size\n",
    " grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    " grid_w, grid_h = grid.size\n",
    "\n",
    " for i, img in enumerate(imgs):\n",
    "  grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    " return grid\n",
    "\n",
    "def download_image(url):\n",
    " try:\n",
    "  response = requests.get(url)\n",
    " except:\n",
    "  return None\n",
    " return Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "images = list(filter(None,[download_image(url) for url in urls]))\n",
    "save_path = \"./training_images\"\n",
    "if not os.path.exists(save_path):\n",
    " os.mkdir(save_path)\n",
    "[image.save(f\"{save_path}/{i}.png\", format=\"png\") for i, image in enumerate(images)]\n",
    "image_grid(images, 1, len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4e50df",
   "metadata": {
    "id": "ad4e50df"
   },
   "source": [
    "## Training\n",
    "\n",
    "If training a person or subject, keep an eye on your project's `logs/{folder}/images/train/samples_scaled_gs-00xxxx` generations.\n",
    "\n",
    "If training a style, keep an eye on your project's `logs/{folder}/images/train/samples_gs-00xxxx` generations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fa5dd66-2ca0-4819-907e-802e25583ae6",
   "metadata": {
    "id": "6fa5dd66-2ca0-4819-907e-802e25583ae6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 23\n",
      "Running on GPUs 0,\n",
      "Loading model from model.ckpt\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 859.52 M params.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 4, 64, 64) = 16384 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Some weights of the model checkpoint at openai/clip-vit-large-patch14 were not used when initializing CLIPTextModel: ['vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.self_attn.out_proj.bias', 'vision_model.encoder.layers.14.layer_norm1.weight', 'vision_model.encoder.layers.22.layer_norm2.bias', 'vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vision_model.encoder.layers.15.mlp.fc2.weight', 'vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_model.encoder.layers.6.layer_norm2.bias', 'vision_model.encoder.layers.12.layer_norm1.weight', 'vision_model.encoder.layers.19.layer_norm2.bias', 'vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_model.encoder.layers.23.layer_norm1.weight', 'vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.encoder.layers.21.layer_norm2.weight', 'vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vision_model.encoder.layers.15.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.mlp.fc2.weight', 'vision_model.encoder.layers.18.mlp.fc1.weight', 'vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_model.encoder.layers.7.layer_norm1.weight', 'vision_model.encoder.layers.22.mlp.fc1.weight', 'vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_model.encoder.layers.14.mlp.fc2.bias', 'vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vision_model.encoder.layers.23.layer_norm2.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.encoder.layers.19.mlp.fc1.weight', 'vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.encoder.layers.20.layer_norm2.bias', 'vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_model.encoder.layers.20.layer_norm2.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.self_attn.v_proj.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.self_attn.q_proj.weight', 'vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.encoder.layers.15.mlp.fc1.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_model.encoder.layers.12.mlp.fc2.bias', 'vision_model.encoder.layers.21.mlp.fc2.bias', 'vision_model.encoder.layers.1.layer_norm2.weight', 'vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.encoder.layers.10.layer_norm2.weight', 'vision_model.encoder.layers.20.layer_norm1.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.encoder.layers.20.mlp.fc1.bias', 'text_projection.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_model.encoder.layers.8.layer_norm2.bias', 'vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vision_model.post_layernorm.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_model.encoder.layers.17.layer_norm2.weight', 'vision_model.post_layernorm.bias', 'vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.encoder.layers.11.layer_norm2.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vision_model.encoder.layers.21.mlp.fc1.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_model.encoder.layers.16.layer_norm1.bias', 'vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vision_model.encoder.layers.5.layer_norm1.bias', 'vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_model.encoder.layers.19.self_attn.out_proj.weight', 'vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_model.encoder.layers.14.self_attn.out_proj.bias', 'vision_model.encoder.layers.1.layer_norm1.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_model.encoder.layers.13.mlp.fc2.bias', 'vision_model.encoder.layers.9.layer_norm1.weight', 'vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vision_model.encoder.layers.10.layer_norm1.weight', 'vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_model.embeddings.patch_embedding.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_model.encoder.layers.11.layer_norm1.bias', 'vision_model.encoder.layers.20.layer_norm1.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vision_model.encoder.layers.15.layer_norm2.bias', 'vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vision_model.encoder.layers.3.layer_norm1.weight', 'vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_model.encoder.layers.17.mlp.fc2.bias', 'vision_model.encoder.layers.18.layer_norm2.bias', 'vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_model.encoder.layers.20.mlp.fc2.bias', 'vision_model.encoder.layers.20.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.layer_norm2.bias', 'vision_model.encoder.layers.12.layer_norm2.bias', 'vision_model.encoder.layers.2.layer_norm1.bias', 'vision_model.encoder.layers.13.layer_norm1.bias', 'vision_model.encoder.layers.18.self_attn.v_proj.bias', 'vision_model.encoder.layers.14.self_attn.q_proj.weight', 'vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.mlp.fc1.weight', 'visual_projection.weight', 'vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.encoder.layers.17.layer_norm1.bias', 'vision_model.encoder.layers.20.mlp.fc1.weight', 'vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.layer_norm2.bias', 'vision_model.encoder.layers.21.layer_norm2.bias', 'vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.encoder.layers.17.layer_norm1.weight', 'vision_model.encoder.layers.22.layer_norm1.weight', 'vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.layer_norm2.weight', 'vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_model.encoder.layers.17.mlp.fc1.bias', 'vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.encoder.layers.18.self_attn.k_proj.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.encoder.layers.23.mlp.fc2.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.encoder.layers.18.mlp.fc2.bias', 'vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.encoder.layers.17.mlp.fc2.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.mlp.fc2.weight', 'vision_model.encoder.layers.18.layer_norm1.bias', 'vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.layer_norm1.bias', 'vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.mlp.fc1.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_model.encoder.layers.3.layer_norm1.bias', 'vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_model.encoder.layers.16.mlp.fc1.bias', 'vision_model.encoder.layers.16.mlp.fc2.bias', 'vision_model.encoder.layers.16.layer_norm2.weight', 'vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.mlp.fc1.bias', 'vision_model.encoder.layers.15.mlp.fc2.bias', 'vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_model.encoder.layers.17.layer_norm2.bias', 'vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vision_model.encoder.layers.9.layer_norm2.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_model.encoder.layers.22.mlp.fc1.bias', 'vision_model.encoder.layers.16.mlp.fc2.weight', 'vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vision_model.encoder.layers.22.layer_norm1.bias', 'vision_model.encoder.layers.12.mlp.fc1.weight', 'vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.layer_norm1.weight', 'vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vision_model.encoder.layers.19.mlp.fc2.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_model.encoder.layers.22.layer_norm2.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.layer_norm2.bias', 'vision_model.encoder.layers.14.layer_norm1.bias', 'vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_model.encoder.layers.22.mlp.fc2.weight', 'vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vision_model.encoder.layers.12.layer_norm2.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vision_model.encoder.layers.21.layer_norm1.weight', 'vision_model.encoder.layers.17.mlp.fc1.weight', 'vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.mlp.fc1.bias', 'vision_model.encoder.layers.18.layer_norm2.weight', 'vision_model.encoder.layers.8.layer_norm1.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_model.encoder.layers.22.self_attn.k_proj.weight', 'vision_model.encoder.layers.8.layer_norm1.bias', 'vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.self_attn.q_proj.bias', 'vision_model.encoder.layers.15.layer_norm1.bias', 'vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.encoder.layers.14.layer_norm2.weight', 'vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.layer_norm1.weight', 'vision_model.encoder.layers.4.layer_norm1.weight', 'vision_model.encoder.layers.14.layer_norm2.bias', 'vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.encoder.layers.5.layer_norm2.weight', 'vision_model.encoder.layers.14.self_attn.k_proj.weight', 'vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.layer_norm2.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.embeddings.position_ids', 'vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.encoder.layers.21.self_attn.out_proj.bias', 'vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.encoder.layers.2.layer_norm1.weight', 'vision_model.encoder.layers.13.self_attn.v_proj.weight', 'vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.mlp.fc1.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.layer_norm2.bias', 'vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_model.encoder.layers.19.mlp.fc2.weight', 'vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.layer_norm1.bias', 'vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vision_model.encoder.layers.7.layer_norm2.bias', 'logit_scale', 'vision_model.embeddings.position_embedding.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.encoder.layers.13.layer_norm2.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vision_model.encoder.layers.14.mlp.fc2.weight', 'vision_model.encoder.layers.20.self_attn.q_proj.bias', 'vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.mlp.fc1.bias', 'vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_model.encoder.layers.0.layer_norm1.bias', 'vision_model.encoder.layers.19.layer_norm1.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.encoder.layers.13.self_attn.k_proj.weight', 'vision_model.encoder.layers.18.mlp.fc1.bias', 'vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.encoder.layers.0.layer_norm1.weight', 'vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vision_model.encoder.layers.23.layer_norm1.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vision_model.encoder.layers.23.self_attn.q_proj.bias', 'vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vision_model.embeddings.class_embedding', 'vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.encoder.layers.19.layer_norm2.weight', 'vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_model.encoder.layers.21.mlp.fc1.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.mlp.fc2.weight', 'vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.layer_norm1.weight', 'vision_model.encoder.layers.23.layer_norm2.bias', 'vision_model.encoder.layers.16.layer_norm2.bias', 'vision_model.pre_layrnorm.bias', 'vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vision_model.encoder.layers.16.layer_norm1.weight', 'vision_model.encoder.layers.7.layer_norm1.bias', 'vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vision_model.pre_layrnorm.weight', 'vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.encoder.layers.23.mlp.fc1.weight', 'vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_model.encoder.layers.2.layer_norm2.weight', 'vision_model.encoder.layers.16.mlp.fc1.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.mlp.fc1.bias', 'vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vision_model.encoder.layers.21.mlp.fc2.weight', 'vision_model.encoder.layers.19.mlp.fc1.bias', 'vision_model.encoder.layers.15.self_attn.q_proj.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.layer_norm1.weight', 'vision_model.encoder.layers.11.layer_norm2.weight', 'vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.encoder.layers.21.layer_norm1.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_model.encoder.layers.13.mlp.fc1.weight', 'vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_model.encoder.layers.6.layer_norm2.weight', 'vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vision_model.encoder.layers.16.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.layer_norm2.weight', 'vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vision_model.encoder.layers.9.layer_norm1.bias', 'vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.mlp.fc2.weight', 'vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_model.encoder.layers.15.layer_norm2.weight', 'vision_model.encoder.layers.22.mlp.fc2.bias', 'vision_model.encoder.layers.18.layer_norm1.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.encoder.layers.23.mlp.fc2.bias', 'vision_model.encoder.layers.7.self_attn.out_proj.weight']\n",
      "- This IS expected if you are initializing CLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Restored from model.ckpt with 0 missing and 2 unexpected keys\n",
      "Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates']\n",
      "/opt/conda/lib/python3.9/site-packages/pytorch_lightning/loggers/test_tube.py:105: LightningDeprecationWarning: The TestTubeLogger is deprecated since v1.5 and will be removed in v1.7. We recommend switching to the `pytorch_lightning.loggers.TensorBoardLogger` as an alternative.\n",
      "  rank_zero_deprecation(\n",
      "Monitoring val/loss_simple_ema as checkpoint metric.\n",
      "Merged modelckpt-cfg: \n",
      "{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': 'logs/training_images2022-10-29T11-38-37_sciadi/checkpoints', 'filename': '{epoch:06}', 'verbose': True, 'save_last': True, 'monitor': 'val/loss_simple_ema', 'save_top_k': 1, 'every_n_train_steps': 500}}\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "#### Data #####\n",
      "train, PersonalizedBase, 2400\n",
      "reg, PersonalizedBase, 15000\n",
      "validation, PersonalizedBase, 24\n",
      "accumulate_grad_batches = 1\n",
      "++++ NOT USING LR SCALING ++++\n",
      "Setting learning rate to 1.00e-06\n",
      "/opt/conda/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:326: LightningDeprecationWarning: Base `LightningModule.on_train_batch_start` hook signature has changed in v1.5. The `dataloader_idx` argument will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "/opt/conda/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:335: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "  rank_zero_deprecation(\n",
      "/opt/conda/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:391: LightningDeprecationWarning: The `Callback.on_pretrain_routine_start` hook has been deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_fit_start` instead.\n",
      "  rank_zero_deprecation(\n",
      "/opt/conda/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:342: LightningDeprecationWarning: Base `Callback.on_train_batch_end` hook signature has changed in v1.5. The `dataloader_idx` argument will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LatentDiffusion: Also optimizing conditioner params!\n",
      "\n",
      "  | Name              | Type               | Params\n",
      "---------------------------------------------------------\n",
      "0 | model             | DiffusionWrapper   | 859 M \n",
      "1 | first_stage_model | AutoencoderKL      | 83.7 M\n",
      "2 | cond_stage_model  | FrozenCLIPEmbedder | 123 M \n",
      "---------------------------------------------------------\n",
      "982 M     Trainable params\n",
      "83.7 M    Non-trainable params\n",
      "1.1 B     Total params\n",
      "4,264.941 Total estimated model params size (MB)\n",
      "Project config\n",
      "model:\n",
      "  base_learning_rate: 1.0e-06\n",
      "  target: ldm.models.diffusion.ddpm.LatentDiffusion\n",
      "  params:\n",
      "    reg_weight: 1.0\n",
      "    linear_start: 0.00085\n",
      "    linear_end: 0.012\n",
      "    num_timesteps_cond: 1\n",
      "    log_every_t: 200\n",
      "    timesteps: 1000\n",
      "    first_stage_key: image\n",
      "    cond_stage_key: caption\n",
      "    image_size: 64\n",
      "    channels: 4\n",
      "    cond_stage_trainable: true\n",
      "    conditioning_key: crossattn\n",
      "    monitor: val/loss_simple_ema\n",
      "    scale_factor: 0.18215\n",
      "    use_ema: false\n",
      "    embedding_reg_weight: 0.0\n",
      "    unfreeze_model: true\n",
      "    model_lr: 1.0e-06\n",
      "    personalization_config:\n",
      "      target: ldm.modules.embedding_manager.EmbeddingManager\n",
      "      params:\n",
      "        placeholder_strings:\n",
      "        - '*'\n",
      "        initializer_words:\n",
      "        - sculpture\n",
      "        per_image_tokens: false\n",
      "        num_vectors_per_token: 1\n",
      "        progressive_words: false\n",
      "    unet_config:\n",
      "      target: ldm.modules.diffusionmodules.openaimodel.UNetModel\n",
      "      params:\n",
      "        image_size: 32\n",
      "        in_channels: 4\n",
      "        out_channels: 4\n",
      "        model_channels: 320\n",
      "        attention_resolutions:\n",
      "        - 4\n",
      "        - 2\n",
      "        - 1\n",
      "        num_res_blocks: 2\n",
      "        channel_mult:\n",
      "        - 1\n",
      "        - 2\n",
      "        - 4\n",
      "        - 4\n",
      "        num_heads: 8\n",
      "        use_spatial_transformer: true\n",
      "        transformer_depth: 1\n",
      "        context_dim: 768\n",
      "        use_checkpoint: true\n",
      "        legacy: false\n",
      "    first_stage_config:\n",
      "      target: ldm.models.autoencoder.AutoencoderKL\n",
      "      params:\n",
      "        embed_dim: 4\n",
      "        monitor: val/rec_loss\n",
      "        ddconfig:\n",
      "          double_z: true\n",
      "          z_channels: 4\n",
      "          resolution: 512\n",
      "          in_channels: 3\n",
      "          out_ch: 3\n",
      "          ch: 128\n",
      "          ch_mult:\n",
      "          - 1\n",
      "          - 2\n",
      "          - 4\n",
      "          - 4\n",
      "          num_res_blocks: 2\n",
      "          attn_resolutions: []\n",
      "          dropout: 0.0\n",
      "        lossconfig:\n",
      "          target: torch.nn.Identity\n",
      "    cond_stage_config:\n",
      "      target: ldm.modules.encoders.modules.FrozenCLIPEmbedder\n",
      "    ckpt_path: model.ckpt\n",
      "data:\n",
      "  target: main.DataModuleFromConfig\n",
      "  params:\n",
      "    batch_size: 1\n",
      "    num_workers: 1\n",
      "    wrap: false\n",
      "    train:\n",
      "      target: ldm.data.personalized.PersonalizedBase\n",
      "      params:\n",
      "        size: 512\n",
      "        set: train\n",
      "        per_image_tokens: false\n",
      "        repeats: 100\n",
      "        coarse_class_text: woman\n",
      "        data_root: /workspace/Dreambooth-Stable-Diffusion/training_images\n",
      "        placeholder_token: sciadi\n",
      "        token_only: false\n",
      "    reg:\n",
      "      target: ldm.data.personalized.PersonalizedBase\n",
      "      params:\n",
      "        size: 512\n",
      "        set: train\n",
      "        reg: true\n",
      "        per_image_tokens: false\n",
      "        repeats: 10\n",
      "        data_root: /workspace/Dreambooth-Stable-Diffusion/regularization_images/woman_ddim\n",
      "        coarse_class_text: woman\n",
      "        placeholder_token: sciadi\n",
      "    validation:\n",
      "      target: ldm.data.personalized.PersonalizedBase\n",
      "      params:\n",
      "        size: 512\n",
      "        set: val\n",
      "        per_image_tokens: false\n",
      "        repeats: 10\n",
      "        coarse_class_text: woman\n",
      "        placeholder_token: sciadi\n",
      "        data_root: /workspace/Dreambooth-Stable-Diffusion/training_images\n",
      "\n",
      "Lightning config\n",
      "modelcheckpoint:\n",
      "  params:\n",
      "    every_n_train_steps: 500\n",
      "callbacks:\n",
      "  image_logger:\n",
      "    target: main.ImageLogger\n",
      "    params:\n",
      "      batch_frequency: 500\n",
      "      max_images: 8\n",
      "      increase_log_steps: false\n",
      "trainer:\n",
      "  benchmark: true\n",
      "  max_steps: 2000\n",
      "  gpus: 0,\n",
      "\n",
      "Sanity Checking: 0it [00:00, ?it/s]/opt/conda/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/conda/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Training: 0it [00:00, ?it/s]/opt/conda/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:2102: LightningDeprecationWarning: `Trainer.root_gpu` is deprecated in v1.6 and will be removed in v1.8. Please use `Trainer.strategy.root_device.index` instead.\n",
      "  rank_zero_deprecation(\n",
      "Epoch 0:   0%|                                         | 0/2424 [00:00<?, ?it/s]/opt/conda/lib/python3.9/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:229: UserWarning: You called `self.log('global_step', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n",
      "Epoch 0:  21%|| 499/2424 [12:20<47:36,  1.48s/it, loss=0.299, v_num=0, train/loData shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "\n",
      "DDIM Sampler:   0%|                                      | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "DDIM Sampler:   2%|                             | 1/50 [00:00<00:06,  7.10it/s]\u001b[A\n",
      "DDIM Sampler:   4%|                            | 2/50 [00:00<00:06,  7.12it/s]\u001b[A\n",
      "DDIM Sampler:   6%|                            | 3/50 [00:00<00:06,  7.13it/s]\u001b[A\n",
      "DDIM Sampler:   8%|                           | 4/50 [00:00<00:06,  7.13it/s]\u001b[A\n",
      "DDIM Sampler:  10%|                           | 5/50 [00:00<00:06,  7.13it/s]\u001b[A\n",
      "DDIM Sampler:  12%|                          | 6/50 [00:00<00:06,  7.13it/s]\u001b[A\n",
      "DDIM Sampler:  14%|                         | 7/50 [00:00<00:06,  7.13it/s]\u001b[A\n",
      "DDIM Sampler:  16%|                         | 8/50 [00:01<00:05,  7.13it/s]\u001b[A\n",
      "DDIM Sampler:  18%|                        | 9/50 [00:01<00:05,  7.13it/s]\u001b[A\n",
      "DDIM Sampler:  20%|                       | 10/50 [00:01<00:05,  7.14it/s]\u001b[A\n",
      "DDIM Sampler:  22%|                      | 11/50 [00:01<00:05,  7.14it/s]\u001b[A\n",
      "DDIM Sampler:  24%|                      | 12/50 [00:01<00:05,  7.13it/s]\u001b[A\n",
      "DDIM Sampler:  26%|                     | 13/50 [00:01<00:05,  7.13it/s]\u001b[A\n",
      "DDIM Sampler:  28%|                     | 14/50 [00:01<00:05,  7.13it/s]\u001b[A\n",
      "DDIM Sampler:  30%|                    | 15/50 [00:02<00:04,  7.13it/s]\u001b[A\n",
      "DDIM Sampler:  32%|                   | 16/50 [00:02<00:04,  7.13it/s]\u001b[A\n",
      "DDIM Sampler:  34%|                   | 17/50 [00:02<00:04,  7.13it/s]\u001b[A\n",
      "DDIM Sampler:  36%|                  | 18/50 [00:02<00:04,  7.14it/s]\u001b[A\n",
      "DDIM Sampler:  38%|                  | 19/50 [00:02<00:04,  7.14it/s]\u001b[A\n",
      "DDIM Sampler:  40%|                 | 20/50 [00:02<00:04,  7.13it/s]\u001b[A\n",
      "DDIM Sampler:  42%|                | 21/50 [00:02<00:04,  7.13it/s]\u001b[A\n",
      "DDIM Sampler:  44%|                | 22/50 [00:03<00:03,  7.14it/s]\u001b[A\n",
      "DDIM Sampler:  46%|               | 23/50 [00:03<00:03,  7.14it/s]\u001b[A\n",
      "DDIM Sampler:  48%|               | 24/50 [00:03<00:03,  7.14it/s]\u001b[A\n",
      "DDIM Sampler:  50%|              | 25/50 [00:03<00:03,  7.14it/s]\u001b[A\n",
      "DDIM Sampler:  52%|              | 26/50 [00:03<00:03,  7.14it/s]\u001b[A\n",
      "DDIM Sampler:  54%|             | 27/50 [00:03<00:03,  7.14it/s]\u001b[A\n",
      "DDIM Sampler:  56%|            | 28/50 [00:03<00:03,  7.14it/s]\u001b[A\n",
      "DDIM Sampler:  58%|            | 29/50 [00:04<00:02,  7.14it/s]\u001b[A\n",
      "DDIM Sampler:  60%|           | 30/50 [00:04<00:02,  7.14it/s]\u001b[A\n",
      "DDIM Sampler:  62%|           | 31/50 [00:04<00:02,  7.14it/s]\u001b[A\n",
      "DDIM Sampler:  64%|          | 32/50 [00:04<00:02,  7.14it/s]\u001b[A\n",
      "DDIM Sampler:  66%|         | 33/50 [00:04<00:02,  7.14it/s]\u001b[A\n",
      "DDIM Sampler:  68%|         | 34/50 [00:04<00:02,  7.14it/s]\u001b[A\n",
      "DDIM Sampler:  70%|        | 35/50 [00:04<00:02,  7.14it/s]\u001b[A\n",
      "DDIM Sampler:  72%|        | 36/50 [00:05<00:01,  7.14it/s]\u001b[A\n",
      "DDIM Sampler:  74%|       | 37/50 [00:05<00:01,  7.14it/s]\u001b[A\n",
      "DDIM Sampler:  76%|       | 38/50 [00:05<00:01,  7.14it/s]\u001b[A\n",
      "DDIM Sampler:  78%|      | 39/50 [00:05<00:01,  7.14it/s]\u001b[A\n",
      "DDIM Sampler:  80%|     | 40/50 [00:05<00:01,  7.14it/s]\u001b[A\n",
      "DDIM Sampler:  82%|     | 41/50 [00:05<00:01,  7.14it/s]\u001b[A\n",
      "DDIM Sampler:  84%|    | 42/50 [00:05<00:01,  7.14it/s]\u001b[A\n",
      "DDIM Sampler:  86%|    | 43/50 [00:06<00:00,  7.14it/s]\u001b[A\n",
      "DDIM Sampler:  88%|   | 44/50 [00:06<00:00,  7.13it/s]\u001b[A\n",
      "DDIM Sampler:  90%|   | 45/50 [00:06<00:00,  7.13it/s]\u001b[A\n",
      "DDIM Sampler:  92%|  | 46/50 [00:06<00:00,  7.13it/s]\u001b[A\n",
      "DDIM Sampler:  94%| | 47/50 [00:06<00:00,  7.13it/s]\u001b[A\n",
      "DDIM Sampler:  96%| | 48/50 [00:06<00:00,  7.13it/s]\u001b[A\n",
      "DDIM Sampler:  98%|| 49/50 [00:06<00:00,  7.13it/s]\u001b[A\n",
      "DDIM Sampler: 100%|| 50/50 [00:07<00:00,  7.13it/s]\u001b[A\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "\n",
      "DDIM Sampler:   0%|                                      | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "DDIM Sampler:   2%|                             | 1/50 [00:02<01:47,  2.20s/it]\u001b[A\n",
      "DDIM Sampler:   4%|                            | 2/50 [00:02<00:49,  1.04s/it]\u001b[A\n",
      "DDIM Sampler:   6%|                            | 3/50 [00:02<00:30,  1.52it/s]\u001b[A\n",
      "DDIM Sampler:   8%|                           | 4/50 [00:02<00:22,  2.07it/s]\u001b[A\n",
      "DDIM Sampler:  10%|                           | 5/50 [00:03<00:17,  2.60it/s]\u001b[A\n",
      "DDIM Sampler:  12%|                          | 6/50 [00:03<00:14,  3.07it/s]\u001b[A\n",
      "DDIM Sampler:  14%|                         | 7/50 [00:03<00:12,  3.47it/s]\u001b[A\n",
      "DDIM Sampler:  16%|                         | 8/50 [00:03<00:11,  3.80it/s]\u001b[A\n",
      "DDIM Sampler:  18%|                        | 9/50 [00:03<00:10,  4.05it/s]\u001b[A\n",
      "DDIM Sampler:  20%|                       | 10/50 [00:04<00:09,  4.24it/s]\u001b[A\n",
      "DDIM Sampler:  22%|                      | 11/50 [00:04<00:08,  4.38it/s]\u001b[A\n",
      "DDIM Sampler:  24%|                      | 12/50 [00:04<00:08,  4.49it/s]\u001b[A\n",
      "DDIM Sampler:  26%|                     | 13/50 [00:04<00:08,  4.56it/s]\u001b[A\n",
      "DDIM Sampler:  28%|                     | 14/50 [00:04<00:07,  4.62it/s]\u001b[A\n",
      "DDIM Sampler:  30%|                    | 15/50 [00:05<00:07,  4.65it/s]\u001b[A\n",
      "DDIM Sampler:  32%|                   | 16/50 [00:05<00:07,  4.68it/s]\u001b[A\n",
      "DDIM Sampler:  34%|                   | 17/50 [00:05<00:07,  4.70it/s]\u001b[A\n",
      "DDIM Sampler:  36%|                  | 18/50 [00:05<00:06,  4.71it/s]\u001b[A\n",
      "DDIM Sampler:  38%|                  | 19/50 [00:06<00:06,  4.72it/s]\u001b[A\n",
      "DDIM Sampler:  40%|                 | 20/50 [00:06<00:06,  4.73it/s]\u001b[A\n",
      "DDIM Sampler:  42%|                | 21/50 [00:06<00:06,  4.73it/s]\u001b[A\n",
      "DDIM Sampler:  44%|                | 22/50 [00:06<00:05,  4.74it/s]\u001b[A\n",
      "DDIM Sampler:  46%|               | 23/50 [00:06<00:05,  4.74it/s]\u001b[A\n",
      "DDIM Sampler:  48%|               | 24/50 [00:07<00:05,  4.74it/s]\u001b[A\n",
      "DDIM Sampler:  50%|              | 25/50 [00:07<00:05,  4.74it/s]\u001b[A\n",
      "DDIM Sampler:  52%|              | 26/50 [00:07<00:05,  4.74it/s]\u001b[A\n",
      "DDIM Sampler:  54%|             | 27/50 [00:07<00:04,  4.74it/s]\u001b[A\n",
      "DDIM Sampler:  56%|            | 28/50 [00:07<00:04,  4.74it/s]\u001b[A\n",
      "DDIM Sampler:  58%|            | 29/50 [00:08<00:04,  4.74it/s]\u001b[A\n",
      "DDIM Sampler:  60%|           | 30/50 [00:08<00:04,  4.74it/s]\u001b[A\n",
      "DDIM Sampler:  62%|           | 31/50 [00:08<00:04,  4.74it/s]\u001b[A\n",
      "DDIM Sampler:  64%|          | 32/50 [00:08<00:03,  4.74it/s]\u001b[A\n",
      "DDIM Sampler:  66%|         | 33/50 [00:08<00:03,  4.74it/s]\u001b[A\n",
      "DDIM Sampler:  68%|         | 34/50 [00:09<00:03,  4.74it/s]\u001b[A\n",
      "DDIM Sampler:  70%|        | 35/50 [00:09<00:03,  4.74it/s]\u001b[A\n",
      "DDIM Sampler:  72%|        | 36/50 [00:09<00:02,  4.74it/s]\u001b[A\n",
      "DDIM Sampler:  74%|       | 37/50 [00:09<00:02,  4.74it/s]\u001b[A\n",
      "DDIM Sampler:  76%|       | 38/50 [00:10<00:02,  4.74it/s]\u001b[A\n",
      "DDIM Sampler:  78%|      | 39/50 [00:10<00:02,  4.74it/s]\u001b[A\n",
      "DDIM Sampler:  80%|     | 40/50 [00:10<00:02,  4.74it/s]\u001b[A\n",
      "DDIM Sampler:  82%|     | 41/50 [00:10<00:01,  4.74it/s]\u001b[A\n",
      "DDIM Sampler:  84%|    | 42/50 [00:10<00:01,  4.74it/s]\u001b[A\n",
      "DDIM Sampler:  86%|    | 43/50 [00:11<00:01,  4.74it/s]\u001b[A\n",
      "DDIM Sampler:  88%|   | 44/50 [00:11<00:01,  4.74it/s]\u001b[A\n",
      "DDIM Sampler:  90%|   | 45/50 [00:11<00:01,  4.74it/s]\u001b[A\n",
      "DDIM Sampler:  92%|  | 46/50 [00:11<00:00,  4.74it/s]\u001b[A\n",
      "DDIM Sampler:  94%| | 47/50 [00:11<00:00,  4.74it/s]\u001b[A\n",
      "DDIM Sampler:  96%| | 48/50 [00:12<00:00,  4.74it/s]\u001b[A\n",
      "DDIM Sampler:  98%|| 49/50 [00:12<00:00,  4.74it/s]\u001b[A\n",
      "DDIM Sampler: 100%|| 50/50 [00:12<00:00,  3.99it/s]\u001b[A\n",
      "Epoch 0:  21%|| 500/2424 [12:43<48:57,  1.53s/it, loss=0.295, v_num=0, train/lo/opt/conda/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:378: UserWarning: `ModelCheckpoint(monitor='val/loss_simple_ema')` could not find the monitored key in the returned metrics: ['train/loss_simple', 'train/loss_simple_step', 'train/loss_vlb', 'train/loss_vlb_step', 'train/loss', 'train/loss_step', 'global_step', 'epoch', 'step']. HINT: Did you call `log('val/loss_simple_ema', value)` in the `LightningModule`?\n",
      "  warning_cache.warn(m)\n",
      "Epoch 0, global step 500: 'val/loss_simple_ema' was not in top 1\n",
      "Prunin' Checkpoint\n",
      "Checkpoint Keys: dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers'])\n",
      "Removing optimizer states from checkpoint\n",
      "This is global step 500.\n",
      "Epoch 0:  41%|| 999/2424 [25:05<35:47,  1.51s/it, loss=0.235, v_num=0, train/lopop from empty list\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "\n",
      "DDIM Sampler:   0%|                                      | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "DDIM Sampler:   2%|                             | 1/50 [00:00<00:06,  7.19it/s]\u001b[A\n",
      "DDIM Sampler:   4%|                            | 2/50 [00:00<00:06,  7.21it/s]\u001b[A\n",
      "DDIM Sampler:   6%|                            | 3/50 [00:00<00:06,  7.22it/s]\u001b[A\n",
      "DDIM Sampler:   8%|                           | 4/50 [00:00<00:06,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  10%|                           | 5/50 [00:00<00:06,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  12%|                          | 6/50 [00:00<00:06,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  14%|                         | 7/50 [00:00<00:05,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  16%|                         | 8/50 [00:01<00:05,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  18%|                        | 9/50 [00:01<00:05,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  20%|                       | 10/50 [00:01<00:05,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  22%|                      | 11/50 [00:01<00:05,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  24%|                      | 12/50 [00:01<00:05,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  26%|                     | 13/50 [00:01<00:05,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  28%|                     | 14/50 [00:01<00:04,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  30%|                    | 15/50 [00:02<00:04,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  32%|                   | 16/50 [00:02<00:04,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  34%|                   | 17/50 [00:02<00:04,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  36%|                  | 18/50 [00:02<00:04,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  38%|                  | 19/50 [00:02<00:04,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  40%|                 | 20/50 [00:02<00:04,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  42%|                | 21/50 [00:02<00:04,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  44%|                | 22/50 [00:03<00:03,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  46%|               | 23/50 [00:03<00:03,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  48%|               | 24/50 [00:03<00:03,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  50%|              | 25/50 [00:03<00:03,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  52%|              | 26/50 [00:03<00:03,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  54%|             | 27/50 [00:03<00:03,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  56%|            | 28/50 [00:03<00:03,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  58%|            | 29/50 [00:04<00:02,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  60%|           | 30/50 [00:04<00:02,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  62%|           | 31/50 [00:04<00:02,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  64%|          | 32/50 [00:04<00:02,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  66%|         | 33/50 [00:04<00:02,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  68%|         | 34/50 [00:04<00:02,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  70%|        | 35/50 [00:04<00:02,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  72%|        | 36/50 [00:04<00:01,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  74%|       | 37/50 [00:05<00:01,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  76%|       | 38/50 [00:05<00:01,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  78%|      | 39/50 [00:05<00:01,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  80%|     | 40/50 [00:05<00:01,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  82%|     | 41/50 [00:05<00:01,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  84%|    | 42/50 [00:05<00:01,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  86%|    | 43/50 [00:05<00:00,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  88%|   | 44/50 [00:06<00:00,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  90%|   | 45/50 [00:06<00:00,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  92%|  | 46/50 [00:06<00:00,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  94%| | 47/50 [00:06<00:00,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  96%| | 48/50 [00:06<00:00,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  98%|| 49/50 [00:06<00:00,  7.24it/s]\u001b[A\n",
      "DDIM Sampler: 100%|| 50/50 [00:06<00:00,  7.23it/s]\u001b[A\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "\n",
      "DDIM Sampler:   0%|                                      | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "DDIM Sampler:   2%|                             | 1/50 [00:00<00:10,  4.79it/s]\u001b[A\n",
      "DDIM Sampler:   4%|                            | 2/50 [00:00<00:10,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:   6%|                            | 3/50 [00:00<00:09,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:   8%|                           | 4/50 [00:00<00:09,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  10%|                           | 5/50 [00:01<00:09,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  12%|                          | 6/50 [00:01<00:09,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  14%|                         | 7/50 [00:01<00:08,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  16%|                         | 8/50 [00:01<00:08,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  18%|                        | 9/50 [00:01<00:08,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  20%|                       | 10/50 [00:02<00:08,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  22%|                      | 11/50 [00:02<00:08,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  24%|                      | 12/50 [00:02<00:07,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  26%|                     | 13/50 [00:02<00:07,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  28%|                     | 14/50 [00:02<00:07,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  30%|                    | 15/50 [00:03<00:07,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  32%|                   | 16/50 [00:03<00:07,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  34%|                   | 17/50 [00:03<00:06,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  36%|                  | 18/50 [00:03<00:06,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  38%|                  | 19/50 [00:03<00:06,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  40%|                 | 20/50 [00:04<00:06,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  42%|                | 21/50 [00:04<00:06,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  44%|                | 22/50 [00:04<00:05,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  46%|               | 23/50 [00:04<00:05,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  48%|               | 24/50 [00:04<00:05,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  50%|              | 25/50 [00:05<00:05,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  52%|              | 26/50 [00:05<00:04,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  54%|             | 27/50 [00:05<00:04,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  56%|            | 28/50 [00:05<00:04,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  58%|            | 29/50 [00:06<00:04,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  60%|           | 30/50 [00:06<00:04,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  62%|           | 31/50 [00:06<00:03,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  64%|          | 32/50 [00:06<00:03,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  66%|         | 33/50 [00:06<00:03,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  68%|         | 34/50 [00:07<00:03,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  70%|        | 35/50 [00:07<00:03,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  72%|        | 36/50 [00:07<00:02,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  74%|       | 37/50 [00:07<00:02,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  76%|       | 38/50 [00:07<00:02,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  78%|      | 39/50 [00:08<00:02,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  80%|     | 40/50 [00:08<00:02,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  82%|     | 41/50 [00:08<00:01,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  84%|    | 42/50 [00:08<00:01,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  86%|    | 43/50 [00:08<00:01,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  88%|   | 44/50 [00:09<00:01,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  90%|   | 45/50 [00:09<00:01,  4.81it/s]\u001b[A\n",
      "DDIM Sampler:  92%|  | 46/50 [00:09<00:00,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  94%| | 47/50 [00:09<00:00,  4.81it/s]\u001b[A\n",
      "DDIM Sampler:  96%| | 48/50 [00:09<00:00,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  98%|| 49/50 [00:10<00:00,  4.80it/s]\u001b[A\n",
      "DDIM Sampler: 100%|| 50/50 [00:10<00:00,  4.80it/s]\u001b[A\n",
      "Epoch 0:  41%|| 1000/2424 [25:24<36:11,  1.52s/it, loss=0.207, v_num=0, train/lEpoch 0, global step 1000: 'val/loss_simple_ema' was not in top 1\n",
      "Prunin' Checkpoint\n",
      "Checkpoint Keys: dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers'])\n",
      "Removing optimizer states from checkpoint\n",
      "This is global step 1000.\n",
      "Epoch 0:  62%|| 1499/2424 [37:47<23:19,  1.51s/it, loss=0.283, v_num=0, train/lpop from empty list\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "\n",
      "DDIM Sampler:   0%|                                      | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "DDIM Sampler:   2%|                             | 1/50 [00:00<00:06,  7.13it/s]\u001b[A\n",
      "DDIM Sampler:   4%|                            | 2/50 [00:00<00:06,  7.19it/s]\u001b[A\n",
      "DDIM Sampler:   6%|                            | 3/50 [00:00<00:06,  7.21it/s]\u001b[A\n",
      "DDIM Sampler:   8%|                           | 4/50 [00:00<00:06,  7.22it/s]\u001b[A\n",
      "DDIM Sampler:  10%|                           | 5/50 [00:00<00:06,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  12%|                          | 6/50 [00:00<00:06,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  14%|                         | 7/50 [00:00<00:05,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  16%|                         | 8/50 [00:01<00:05,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  18%|                        | 9/50 [00:01<00:05,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  20%|                       | 10/50 [00:01<00:05,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  22%|                      | 11/50 [00:01<00:05,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  24%|                      | 12/50 [00:01<00:05,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  26%|                     | 13/50 [00:01<00:05,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  28%|                     | 14/50 [00:01<00:04,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  30%|                    | 15/50 [00:02<00:04,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  32%|                   | 16/50 [00:02<00:04,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  34%|                   | 17/50 [00:02<00:04,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  36%|                  | 18/50 [00:02<00:04,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  38%|                  | 19/50 [00:02<00:04,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  40%|                 | 20/50 [00:02<00:04,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  42%|                | 21/50 [00:02<00:04,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  44%|                | 22/50 [00:03<00:03,  7.22it/s]\u001b[A\n",
      "DDIM Sampler:  46%|               | 23/50 [00:03<00:03,  7.22it/s]\u001b[A\n",
      "DDIM Sampler:  48%|               | 24/50 [00:03<00:03,  7.22it/s]\u001b[A\n",
      "DDIM Sampler:  50%|              | 25/50 [00:03<00:03,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  52%|              | 26/50 [00:03<00:03,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  54%|             | 27/50 [00:03<00:03,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  56%|            | 28/50 [00:03<00:03,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  58%|            | 29/50 [00:04<00:02,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  60%|           | 30/50 [00:04<00:02,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  62%|           | 31/50 [00:04<00:02,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  64%|          | 32/50 [00:04<00:02,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  66%|         | 33/50 [00:04<00:02,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  68%|         | 34/50 [00:04<00:02,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  70%|        | 35/50 [00:04<00:02,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  72%|        | 36/50 [00:04<00:01,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  74%|       | 37/50 [00:05<00:01,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  76%|       | 38/50 [00:05<00:01,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  78%|      | 39/50 [00:05<00:01,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  80%|     | 40/50 [00:05<00:01,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  82%|     | 41/50 [00:05<00:01,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  84%|    | 42/50 [00:05<00:01,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  86%|    | 43/50 [00:05<00:00,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  88%|   | 44/50 [00:06<00:00,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  90%|   | 45/50 [00:06<00:00,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  92%|  | 46/50 [00:06<00:00,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  94%| | 47/50 [00:06<00:00,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  96%| | 48/50 [00:06<00:00,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  98%|| 49/50 [00:06<00:00,  7.23it/s]\u001b[A\n",
      "DDIM Sampler: 100%|| 50/50 [00:06<00:00,  7.23it/s]\u001b[A\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "\n",
      "DDIM Sampler:   0%|                                      | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "DDIM Sampler:   2%|                             | 1/50 [00:00<00:10,  4.77it/s]\u001b[A\n",
      "DDIM Sampler:   4%|                            | 2/50 [00:00<00:10,  4.79it/s]\u001b[A\n",
      "DDIM Sampler:   6%|                            | 3/50 [00:00<00:09,  4.79it/s]\u001b[A\n",
      "DDIM Sampler:   8%|                           | 4/50 [00:00<00:09,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  10%|                           | 5/50 [00:01<00:09,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  12%|                          | 6/50 [00:01<00:09,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  14%|                         | 7/50 [00:01<00:08,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  16%|                         | 8/50 [00:01<00:08,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  18%|                        | 9/50 [00:01<00:08,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  20%|                       | 10/50 [00:02<00:08,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  22%|                      | 11/50 [00:02<00:08,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  24%|                      | 12/50 [00:02<00:07,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  26%|                     | 13/50 [00:02<00:07,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  28%|                     | 14/50 [00:02<00:07,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  30%|                    | 15/50 [00:03<00:07,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  32%|                   | 16/50 [00:03<00:07,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  34%|                   | 17/50 [00:03<00:06,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  36%|                  | 18/50 [00:03<00:06,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  38%|                  | 19/50 [00:03<00:06,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  40%|                 | 20/50 [00:04<00:06,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  42%|                | 21/50 [00:04<00:06,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  44%|                | 22/50 [00:04<00:05,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  46%|               | 23/50 [00:04<00:05,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  48%|               | 24/50 [00:05<00:05,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  50%|              | 25/50 [00:05<00:05,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  52%|              | 26/50 [00:05<00:05,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  54%|             | 27/50 [00:05<00:04,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  56%|            | 28/50 [00:05<00:04,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  58%|            | 29/50 [00:06<00:04,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  60%|           | 30/50 [00:06<00:04,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  62%|           | 31/50 [00:06<00:03,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  64%|          | 32/50 [00:06<00:03,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  66%|         | 33/50 [00:06<00:03,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  68%|         | 34/50 [00:07<00:03,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  70%|        | 35/50 [00:07<00:03,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  72%|        | 36/50 [00:07<00:02,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  74%|       | 37/50 [00:07<00:02,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  76%|       | 38/50 [00:07<00:02,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  78%|      | 39/50 [00:08<00:02,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  80%|     | 40/50 [00:08<00:02,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  82%|     | 41/50 [00:08<00:01,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  84%|    | 42/50 [00:08<00:01,  4.79it/s]\u001b[A\n",
      "DDIM Sampler:  86%|    | 43/50 [00:08<00:01,  4.79it/s]\u001b[A\n",
      "DDIM Sampler:  88%|   | 44/50 [00:09<00:01,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  90%|   | 45/50 [00:09<00:01,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  92%|  | 46/50 [00:09<00:00,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  94%| | 47/50 [00:09<00:00,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  96%| | 48/50 [00:10<00:00,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  98%|| 49/50 [00:10<00:00,  4.80it/s]\u001b[A\n",
      "DDIM Sampler: 100%|| 50/50 [00:10<00:00,  4.80it/s]\u001b[A\n",
      "Epoch 0:  62%|| 1500/2424 [38:07<23:29,  1.52s/it, loss=0.278, v_num=0, train/lEpoch 0, global step 1500: 'val/loss_simple_ema' was not in top 1\n",
      "Prunin' Checkpoint\n",
      "Checkpoint Keys: dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers'])\n",
      "Removing optimizer states from checkpoint\n",
      "This is global step 1500.\n",
      "Epoch 0:  82%|| 1999/2424 [50:30<10:44,  1.52s/it, loss=0.282, v_num=0, train/lpop from empty list\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "\n",
      "DDIM Sampler:   0%|                                      | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "DDIM Sampler:   2%|                             | 1/50 [00:00<00:06,  7.13it/s]\u001b[A\n",
      "DDIM Sampler:   4%|                            | 2/50 [00:00<00:06,  7.18it/s]\u001b[A\n",
      "DDIM Sampler:   6%|                            | 3/50 [00:00<00:06,  7.19it/s]\u001b[A\n",
      "DDIM Sampler:   8%|                           | 4/50 [00:00<00:06,  7.21it/s]\u001b[A\n",
      "DDIM Sampler:  10%|                           | 5/50 [00:00<00:06,  7.21it/s]\u001b[A\n",
      "DDIM Sampler:  12%|                          | 6/50 [00:00<00:06,  7.22it/s]\u001b[A\n",
      "DDIM Sampler:  14%|                         | 7/50 [00:00<00:05,  7.22it/s]\u001b[A\n",
      "DDIM Sampler:  16%|                         | 8/50 [00:01<00:05,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  18%|                        | 9/50 [00:01<00:05,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  20%|                       | 10/50 [00:01<00:05,  7.22it/s]\u001b[A\n",
      "DDIM Sampler:  22%|                      | 11/50 [00:01<00:05,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  24%|                      | 12/50 [00:01<00:05,  7.22it/s]\u001b[A\n",
      "DDIM Sampler:  26%|                     | 13/50 [00:01<00:05,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  28%|                     | 14/50 [00:01<00:04,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  30%|                    | 15/50 [00:02<00:04,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  32%|                   | 16/50 [00:02<00:04,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  34%|                   | 17/50 [00:02<00:04,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  36%|                  | 18/50 [00:02<00:04,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  38%|                  | 19/50 [00:02<00:04,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  40%|                 | 20/50 [00:02<00:04,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  42%|                | 21/50 [00:02<00:04,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  44%|                | 22/50 [00:03<00:03,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  46%|               | 23/50 [00:03<00:03,  7.24it/s]\u001b[A\n",
      "DDIM Sampler:  48%|               | 24/50 [00:03<00:03,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  50%|              | 25/50 [00:03<00:03,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  52%|              | 26/50 [00:03<00:03,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  54%|             | 27/50 [00:03<00:03,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  56%|            | 28/50 [00:03<00:03,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  58%|            | 29/50 [00:04<00:02,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  60%|           | 30/50 [00:04<00:02,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  62%|           | 31/50 [00:04<00:02,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  64%|          | 32/50 [00:04<00:02,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  66%|         | 33/50 [00:04<00:02,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  68%|         | 34/50 [00:04<00:02,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  70%|        | 35/50 [00:04<00:02,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  72%|        | 36/50 [00:04<00:01,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  74%|       | 37/50 [00:05<00:01,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  76%|       | 38/50 [00:05<00:01,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  78%|      | 39/50 [00:05<00:01,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  80%|     | 40/50 [00:05<00:01,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  82%|     | 41/50 [00:05<00:01,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  84%|    | 42/50 [00:05<00:01,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  86%|    | 43/50 [00:05<00:00,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  88%|   | 44/50 [00:06<00:00,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  90%|   | 45/50 [00:06<00:00,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  92%|  | 46/50 [00:06<00:00,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  94%| | 47/50 [00:06<00:00,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  96%| | 48/50 [00:06<00:00,  7.23it/s]\u001b[A\n",
      "DDIM Sampler:  98%|| 49/50 [00:06<00:00,  7.23it/s]\u001b[A\n",
      "DDIM Sampler: 100%|| 50/50 [00:06<00:00,  7.23it/s]\u001b[A\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "\n",
      "DDIM Sampler:   0%|                                      | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "DDIM Sampler:   2%|                             | 1/50 [00:00<00:10,  4.78it/s]\u001b[A\n",
      "DDIM Sampler:   4%|                            | 2/50 [00:00<00:10,  4.79it/s]\u001b[A\n",
      "DDIM Sampler:   6%|                            | 3/50 [00:00<00:09,  4.79it/s]\u001b[A\n",
      "DDIM Sampler:   8%|                           | 4/50 [00:00<00:09,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  10%|                           | 5/50 [00:01<00:09,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  12%|                          | 6/50 [00:01<00:09,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  14%|                         | 7/50 [00:01<00:08,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  16%|                         | 8/50 [00:01<00:08,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  18%|                        | 9/50 [00:01<00:08,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  20%|                       | 10/50 [00:02<00:08,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  22%|                      | 11/50 [00:02<00:08,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  24%|                      | 12/50 [00:02<00:07,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  26%|                     | 13/50 [00:02<00:07,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  28%|                     | 14/50 [00:02<00:07,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  30%|                    | 15/50 [00:03<00:07,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  32%|                   | 16/50 [00:03<00:07,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  34%|                   | 17/50 [00:03<00:06,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  36%|                  | 18/50 [00:03<00:06,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  38%|                  | 19/50 [00:03<00:06,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  40%|                 | 20/50 [00:04<00:06,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  42%|                | 21/50 [00:04<00:06,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  44%|                | 22/50 [00:04<00:05,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  46%|               | 23/50 [00:04<00:05,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  48%|               | 24/50 [00:05<00:05,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  50%|              | 25/50 [00:05<00:05,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  52%|              | 26/50 [00:05<00:05,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  54%|             | 27/50 [00:05<00:04,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  56%|            | 28/50 [00:05<00:04,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  58%|            | 29/50 [00:06<00:04,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  60%|           | 30/50 [00:06<00:04,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  62%|           | 31/50 [00:06<00:03,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  64%|          | 32/50 [00:06<00:03,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  66%|         | 33/50 [00:06<00:03,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  68%|         | 34/50 [00:07<00:03,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  70%|        | 35/50 [00:07<00:03,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  72%|        | 36/50 [00:07<00:02,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  74%|       | 37/50 [00:07<00:02,  4.79it/s]\u001b[A\n",
      "DDIM Sampler:  76%|       | 38/50 [00:07<00:02,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  78%|      | 39/50 [00:08<00:02,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  80%|     | 40/50 [00:08<00:02,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  82%|     | 41/50 [00:08<00:01,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  84%|    | 42/50 [00:08<00:01,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  86%|    | 43/50 [00:08<00:01,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  88%|   | 44/50 [00:09<00:01,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  90%|   | 45/50 [00:09<00:01,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  92%|  | 46/50 [00:09<00:00,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  94%| | 47/50 [00:09<00:00,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  96%| | 48/50 [00:10<00:00,  4.80it/s]\u001b[A\n",
      "DDIM Sampler:  98%|| 49/50 [00:10<00:00,  4.80it/s]\u001b[A\n",
      "DDIM Sampler: 100%|| 50/50 [00:10<00:00,  4.80it/s]\u001b[A\n",
      "Epoch 0:  83%|| 2000/2424 [50:49<10:46,  1.52s/it, loss=0.282, v_num=0, train/lEpoch 0, global step 2000: 'val/loss_simple_ema' was not in top 1\n",
      "Prunin' Checkpoint\n",
      "Checkpoint Keys: dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers'])\n",
      "Removing optimizer states from checkpoint\n",
      "This is global step 2000.\n",
      "/opt/conda/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:2102: LightningDeprecationWarning: `Trainer.root_gpu` is deprecated in v1.6 and will be removed in v1.8. Please use `Trainer.strategy.root_device.index` instead.\n",
      "  rank_zero_deprecation(\n",
      "/opt/conda/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:2028: LightningDeprecationWarning: `Trainer.training_type_plugin` is deprecated in v1.6 and will be removed in v1.8. Use `Trainer.strategy` instead.\n",
      "  rank_zero_deprecation(\n",
      "Average Epoch time: 3053.09 seconds\n",
      "Average Peak memory 25684.99MiB\n",
      "Epoch 0:  83%|| 2000/2424 [50:53<10:47,  1.53s/it, loss=0.282, v_num=0, train/l\n",
      "Training complete. max_training_steps reached or we blew up.\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "# This isn't used for training, just to help you remember what your trained into the model.\n",
    "project_name = \"sciadi\"\n",
    "\n",
    "# MAX STEPS\n",
    "# How many steps do you want to train for?\n",
    "max_training_steps = 2000\n",
    "\n",
    "# Match class_word to the category of the regularization images you chose above.\n",
    "class_word = \"woman\" # typical uses are \"man\", \"person\", \"woman\"\n",
    "\n",
    "# This is the unique token you are incorporating into the stable diffusion model.\n",
    "token = \"sciadi\"\n",
    "\n",
    "\n",
    "reg_data_root = \"/workspace/Dreambooth-Stable-Diffusion/regularization_images/\" + dataset\n",
    "\n",
    "!rm -rf training_images/.ipynb_checkpoints\n",
    "!python \"main.py\" \\\n",
    " --base configs/stable-diffusion/v1-finetune_unfrozen.yaml \\\n",
    " -t \\\n",
    " --actual_resume \"model.ckpt\" \\\n",
    " --reg_data_root \"{reg_data_root}\" \\\n",
    " -n \"{project_name}\" \\\n",
    " --gpus 0, \\\n",
    " --data_root \"/workspace/Dreambooth-Stable-Diffusion/training_images\" \\\n",
    " --max_training_steps {max_training_steps} \\\n",
    " --class_word \"{class_word}\" \\\n",
    " --token \"{token}\" \\\n",
    " --no-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc49d0bd",
   "metadata": {},
   "source": [
    "## Copy and name the checkpoint file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e14ab204",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download your trained model file from trained_models/2022-10-29T12-41-29_sciadi_24_training_images_2000_max_training_steps_sciadi_token_woman_class_word.ckpt and use in your favorite Stable Diffusion repo!\n"
     ]
    }
   ],
   "source": [
    "# Copy the checkpoint into our `trained_models` folder\n",
    "\n",
    "directory_paths = !ls -d logs/*\n",
    "last_checkpoint_file = directory_paths[-1] + \"/checkpoints/last.ckpt\"\n",
    "training_images = !find training_images/*\n",
    "date_string = !date +\"%Y-%m-%dT%H-%M-%S\"\n",
    "file_name = date_string[-1] + \"_\" + project_name + \"_\" + str(len(training_images)) + \"_training_images_\" +  str(max_training_steps) + \"_max_training_steps_\" + token + \"_token_\" + class_word + \"_class_word.ckpt\"\n",
    "\n",
    "file_name = file_name.replace(\" \", \"_\")\n",
    "\n",
    "!mkdir -p trained_models\n",
    "!mv \"{last_checkpoint_file}\" \"trained_models/{file_name}\"\n",
    "\n",
    "print(\"Download your trained model file from trained_models/\" + file_name + \" and use in your favorite Stable Diffusion repo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd291be7",
   "metadata": {},
   "source": [
    "# Optional - Upload to google drive\n",
    "* run the following commands in a new `terminal` in the `Dreambooth-Stable-Diffusion` directory\n",
    "* `chmod +x ./gdrive`\n",
    "* `./gdrive about`\n",
    "* `paste your token here after navigating to the link`\n",
    "* `./gdrive upload trained_models/{file_name.ckpt}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de11b072-7220-4e3a-9110-bbf82da1bc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication needed\n",
      "Go to the following url in your browser:\n",
      "https://accounts.google.com/o/oauth2/auth?access_type=offline&client_id=367116221053-7n0vf5akeru7on6o2fjinrecpdoe99eg.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&state=state\n",
      "\n",
      "Enter verification code: ^C\n",
      "Authentication needed\n",
      "Go to the following url in your browser:\n",
      "https://accounts.google.com/o/oauth2/auth?access_type=offline&client_id=367116221053-7n0vf5akeru7on6o2fjinrecpdoe99eg.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&state=state\n",
      "\n",
      "Enter verification code: ^C\n"
     ]
    }
   ],
   "source": [
    "!chmod +x ./gdrive\n",
    "!./gdrive about\n",
    "!./gdrive upload trained_models/{file_name.ckpt}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a90ac5c",
   "metadata": {},
   "source": [
    "# Big Important Note!\n",
    "\n",
    "The way to use your token is `<token> <class>` ie `joepenna person` and not just `joepenna`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28d0139",
   "metadata": {},
   "source": [
    "## Generate Images With Your Trained Model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80ddb03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ./trained_models/2022-10-29T12-41-29_sciadi_24_training_images_2000_max_training_steps_sciadi_token_woman_class_word.ckpt\n",
      "Global Step: 2000\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 859.52 M params.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "Your samples are ready and waiting for you here: \n",
      "outputs/txt2img-samples \n",
      " \n",
      "Enjoy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Some weights of the model checkpoint at openai/clip-vit-large-patch14 were not used when initializing CLIPTextModel: ['vision_model.encoder.layers.3.layer_norm2.bias', 'vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_model.encoder.layers.23.layer_norm2.weight', 'vision_model.encoder.layers.18.mlp.fc2.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.layer_norm2.weight', 'vision_model.encoder.layers.13.layer_norm1.weight', 'vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_model.encoder.layers.0.layer_norm1.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vision_model.encoder.layers.23.mlp.fc1.weight', 'vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.encoder.layers.13.self_attn.q_proj.weight', 'vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vision_model.encoder.layers.19.layer_norm2.bias', 'vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vision_model.encoder.layers.22.self_attn.v_proj.weight', 'vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_model.encoder.layers.21.mlp.fc1.weight', 'vision_model.encoder.layers.13.mlp.fc1.bias', 'vision_model.encoder.layers.14.self_attn.k_proj.weight', 'vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vision_model.embeddings.position_ids', 'vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vision_model.encoder.layers.8.layer_norm1.bias', 'vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_model.encoder.layers.17.mlp.fc1.weight', 'vision_model.encoder.layers.0.layer_norm1.bias', 'vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vision_model.encoder.layers.23.self_attn.q_proj.bias', 'vision_model.encoder.layers.23.layer_norm1.bias', 'vision_model.encoder.layers.16.layer_norm1.bias', 'vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_model.encoder.layers.15.layer_norm1.bias', 'vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vision_model.encoder.layers.22.layer_norm2.bias', 'vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_model.encoder.layers.19.mlp.fc2.bias', 'vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.layer_norm2.weight', 'vision_model.encoder.layers.14.mlp.fc2.weight', 'vision_model.encoder.layers.20.layer_norm1.weight', 'vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.encoder.layers.13.mlp.fc1.weight', 'vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_model.encoder.layers.18.self_attn.v_proj.bias', 'vision_model.encoder.layers.17.layer_norm1.weight', 'vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.mlp.fc2.bias', 'vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.mlp.fc2.bias', 'vision_model.encoder.layers.14.self_attn.q_proj.bias', 'vision_model.encoder.layers.16.self_attn.v_proj.bias', 'vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.layer_norm2.bias', 'vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_model.encoder.layers.14.layer_norm1.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.encoder.layers.23.layer_norm2.bias', 'vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.encoder.layers.18.layer_norm2.weight', 'vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vision_model.encoder.layers.15.self_attn.k_proj.weight', 'vision_model.encoder.layers.20.mlp.fc1.weight', 'vision_model.encoder.layers.18.layer_norm2.bias', 'vision_model.encoder.layers.21.layer_norm1.bias', 'vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_model.encoder.layers.22.mlp.fc1.bias', 'vision_model.encoder.layers.16.mlp.fc1.bias', 'logit_scale', 'vision_model.encoder.layers.20.mlp.fc1.bias', 'vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.encoder.layers.16.layer_norm1.weight', 'vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vision_model.encoder.layers.5.layer_norm1.weight', 'visual_projection.weight', 'vision_model.encoder.layers.21.mlp.fc1.bias', 'vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_model.encoder.layers.12.mlp.fc2.weight', 'vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.encoder.layers.22.layer_norm1.weight', 'vision_model.encoder.layers.1.layer_norm2.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_model.encoder.layers.23.mlp.fc1.bias', 'vision_model.encoder.layers.11.layer_norm1.weight', 'vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vision_model.encoder.layers.19.mlp.fc2.weight', 'vision_model.encoder.layers.14.layer_norm2.bias', 'vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.encoder.layers.16.layer_norm2.bias', 'vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vision_model.encoder.layers.13.self_attn.k_proj.weight', 'vision_model.encoder.layers.19.mlp.fc1.weight', 'vision_model.encoder.layers.20.mlp.fc2.weight', 'vision_model.encoder.layers.15.mlp.fc1.bias', 'vision_model.encoder.layers.9.layer_norm1.weight', 'vision_model.encoder.layers.17.mlp.fc2.weight', 'vision_model.encoder.layers.15.layer_norm2.weight', 'vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vision_model.encoder.layers.14.self_attn.out_proj.bias', 'vision_model.encoder.layers.5.layer_norm1.bias', 'vision_model.encoder.layers.4.layer_norm2.bias', 'vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.encoder.layers.21.layer_norm1.weight', 'vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.layer_norm1.weight', 'vision_model.encoder.layers.19.self_attn.out_proj.weight', 'vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vision_model.encoder.layers.3.layer_norm1.bias', 'vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.encoder.layers.21.self_attn.out_proj.bias', 'vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.layer_norm1.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_model.encoder.layers.12.layer_norm1.bias', 'vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vision_model.encoder.layers.20.mlp.fc2.bias', 'vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.layer_norm1.weight', 'vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.encoder.layers.14.layer_norm2.weight', 'vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vision_model.encoder.layers.2.layer_norm2.weight', 'vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.layer_norm1.bias', 'vision_model.encoder.layers.20.layer_norm1.bias', 'vision_model.encoder.layers.13.layer_norm2.bias', 'vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.encoder.layers.12.layer_norm1.weight', 'vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.embeddings.class_embedding', 'vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.self_attn.out_proj.bias', 'vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.layer_norm2.bias', 'vision_model.encoder.layers.4.layer_norm2.weight', 'vision_model.encoder.layers.8.layer_norm1.weight', 'vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.bias', 'text_projection.weight', 'vision_model.encoder.layers.20.self_attn.v_proj.bias', 'vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_model.encoder.layers.22.layer_norm1.bias', 'vision_model.encoder.layers.10.layer_norm1.weight', 'vision_model.encoder.layers.15.mlp.fc2.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_model.encoder.layers.19.mlp.fc1.bias', 'vision_model.encoder.layers.15.layer_norm1.weight', 'vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vision_model.encoder.layers.18.layer_norm1.bias', 'vision_model.encoder.layers.9.layer_norm2.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_model.encoder.layers.14.mlp.fc1.weight', 'vision_model.post_layernorm.weight', 'vision_model.encoder.layers.7.layer_norm1.weight', 'vision_model.encoder.layers.14.mlp.fc2.bias', 'vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.encoder.layers.14.layer_norm1.bias', 'vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_model.encoder.layers.15.layer_norm2.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.encoder.layers.19.layer_norm2.weight', 'vision_model.encoder.layers.21.mlp.fc2.weight', 'vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.mlp.fc1.bias', 'vision_model.encoder.layers.23.layer_norm1.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.embeddings.position_embedding.weight', 'vision_model.encoder.layers.13.mlp.fc2.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_model.encoder.layers.16.mlp.fc2.weight', 'vision_model.encoder.layers.18.mlp.fc1.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.encoder.layers.9.layer_norm1.bias', 'vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_model.encoder.layers.20.layer_norm2.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.layer_norm2.weight', 'vision_model.encoder.layers.17.layer_norm1.bias', 'vision_model.encoder.layers.17.layer_norm2.bias', 'vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.mlp.fc2.bias', 'vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_model.encoder.layers.22.mlp.fc1.weight', 'vision_model.encoder.layers.18.layer_norm1.weight', 'vision_model.encoder.layers.21.mlp.fc2.bias', 'vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_model.encoder.layers.20.layer_norm2.bias', 'vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vision_model.encoder.layers.6.layer_norm2.weight', 'vision_model.encoder.layers.12.mlp.fc2.bias', 'vision_model.encoder.layers.22.mlp.fc2.weight', 'vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vision_model.encoder.layers.16.mlp.fc1.weight', 'vision_model.encoder.layers.23.mlp.fc2.bias', 'vision_model.encoder.layers.8.layer_norm2.bias', 'vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vision_model.encoder.layers.2.layer_norm1.weight', 'vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_model.encoder.layers.7.layer_norm1.bias', 'vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vision_model.encoder.layers.7.layer_norm2.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_model.encoder.layers.16.layer_norm2.weight', 'vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_model.encoder.layers.18.mlp.fc2.weight', 'vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vision_model.encoder.layers.0.layer_norm2.bias', 'vision_model.encoder.layers.12.layer_norm2.weight', 'vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.encoder.layers.21.layer_norm2.weight', 'vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_model.encoder.layers.21.layer_norm2.bias', 'vision_model.encoder.layers.12.mlp.fc1.weight', 'vision_model.embeddings.patch_embedding.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_model.post_layernorm.bias', 'vision_model.encoder.layers.7.layer_norm2.bias', 'vision_model.encoder.layers.12.mlp.fc1.bias', 'vision_model.encoder.layers.14.mlp.fc1.bias', 'vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.encoder.layers.6.layer_norm2.bias', 'vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_model.encoder.layers.13.layer_norm1.bias', 'vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.self_attn.q_proj.weight', 'vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.layer_norm1.bias', 'vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.encoder.layers.22.self_attn.k_proj.weight', 'vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.encoder.layers.17.layer_norm2.weight', 'vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_model.encoder.layers.22.layer_norm2.weight', 'vision_model.pre_layrnorm.bias', 'vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vision_model.encoder.layers.22.mlp.fc2.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_model.encoder.layers.13.layer_norm2.weight', 'vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vision_model.pre_layrnorm.weight', 'vision_model.encoder.layers.2.layer_norm1.bias', 'vision_model.encoder.layers.16.mlp.fc2.bias', 'vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_model.encoder.layers.17.mlp.fc1.bias', 'vision_model.encoder.layers.4.layer_norm1.weight', 'vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vision_model.encoder.layers.15.mlp.fc1.weight', 'vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.mlp.fc2.weight', 'vision_model.encoder.layers.12.layer_norm2.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.encoder.layers.18.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vision_model.encoder.layers.14.self_attn.q_proj.weight']\n",
      "- This IS expected if you are initializing CLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\n",
      "Sampling:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "\n",
      "data:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:   2%|2         | 1/50 [00:02<01:43,  2.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:   4%|4         | 2/50 [00:02<00:54,  1.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:   6%|6         | 3/50 [00:02<00:38,  1.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:   8%|8         | 4/50 [00:03<00:29,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  10%|#         | 5/50 [00:03<00:24,  1.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  12%|#2        | 6/50 [00:04<00:21,  2.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  14%|#4        | 7/50 [00:04<00:19,  2.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  16%|#6        | 8/50 [00:04<00:18,  2.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  18%|#8        | 9/50 [00:05<00:16,  2.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  20%|##        | 10/50 [00:05<00:16,  2.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  22%|##2       | 11/50 [00:06<00:15,  2.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  24%|##4       | 12/50 [00:06<00:15,  2.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  26%|##6       | 13/50 [00:06<00:14,  2.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  28%|##8       | 14/50 [00:07<00:14,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  30%|###       | 15/50 [00:07<00:13,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  32%|###2      | 16/50 [00:08<00:13,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  34%|###4      | 17/50 [00:08<00:12,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  36%|###6      | 18/50 [00:08<00:12,  2.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  38%|###8      | 19/50 [00:11<00:29,  1.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  40%|####      | 20/50 [00:11<00:22,  1.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  42%|####2     | 21/50 [00:11<00:17,  1.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  44%|####4     | 22/50 [00:14<00:32,  1.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  46%|####6     | 23/50 [00:14<00:24,  1.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  48%|####8     | 24/50 [00:14<00:19,  1.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  50%|#####     | 25/50 [00:17<00:30,  1.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  52%|#####2    | 26/50 [00:17<00:22,  1.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  54%|#####4    | 27/50 [00:17<00:17,  1.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  56%|#####6    | 28/50 [00:19<00:26,  1.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  58%|#####8    | 29/50 [00:20<00:19,  1.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  60%|######    | 30/50 [00:20<00:15,  1.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  62%|######2   | 31/50 [00:20<00:11,  1.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  64%|######4   | 32/50 [00:23<00:20,  1.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  66%|######6   | 33/50 [00:23<00:15,  1.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  68%|######8   | 34/50 [00:24<00:12,  1.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  70%|#######   | 35/50 [00:24<00:09,  1.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  72%|#######2  | 36/50 [00:24<00:08,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  74%|#######4  | 37/50 [00:25<00:06,  1.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  76%|#######6  | 38/50 [00:25<00:05,  2.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  78%|#######8  | 39/50 [00:26<00:05,  2.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  80%|########  | 40/50 [00:26<00:04,  2.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  82%|########2 | 41/50 [00:26<00:03,  2.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  84%|########4 | 42/50 [00:27<00:03,  2.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  86%|########6 | 43/50 [00:27<00:02,  2.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  88%|########8 | 44/50 [00:28<00:02,  2.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  90%|######### | 45/50 [00:28<00:02,  2.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  92%|#########2| 46/50 [00:28<00:01,  2.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  94%|#########3| 47/50 [00:29<00:01,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  96%|#########6| 48/50 [00:29<00:00,  2.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  98%|#########8| 49/50 [00:29<00:00,  2.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler: 100%|##########| 50/50 [00:30<00:00,  2.55it/s]\u001b[A\u001b[A\n",
      "DDIM Sampler: 100%|##########| 50/50 [00:30<00:00,  1.65it/s]\n",
      "\n",
      "\n",
      "data: 100%|##########| 1/1 [00:37<00:00, 37.48s/it]\u001b[A\n",
      "data: 100%|##########| 1/1 [00:37<00:00, 37.48s/it]\n",
      "\n",
      "Sampling:  25%|##5       | 1/4 [00:37<01:52, 37.48s/it]\n",
      "\n",
      "data:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:   2%|2         | 1/50 [00:03<02:47,  3.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:   4%|4         | 2/50 [00:03<01:19,  1.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:   6%|6         | 3/50 [00:04<00:48,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:   8%|8         | 4/50 [00:04<00:33,  1.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  10%|#         | 5/50 [00:06<00:56,  1.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  12%|#2        | 6/50 [00:06<00:40,  1.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  14%|#4        | 7/50 [00:07<00:30,  1.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  16%|#6        | 8/50 [00:09<00:50,  1.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  18%|#8        | 9/50 [00:09<00:37,  1.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  20%|##        | 10/50 [00:09<00:28,  1.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  22%|##2       | 11/50 [00:12<00:46,  1.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  24%|##4       | 12/50 [00:12<00:34,  1.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  26%|##6       | 13/50 [00:12<00:26,  1.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  28%|##8       | 14/50 [00:15<00:43,  1.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  30%|###       | 15/50 [00:17<00:50,  1.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  32%|###2      | 16/50 [00:19<00:58,  1.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  34%|###4      | 17/50 [00:22<01:04,  1.97s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  36%|###6      | 18/50 [00:25<01:17,  2.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  38%|###8      | 19/50 [00:25<00:55,  1.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  40%|####      | 20/50 [00:26<00:39,  1.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  42%|####2     | 21/50 [00:28<00:45,  1.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  44%|####4     | 22/50 [00:28<00:34,  1.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  46%|####6     | 23/50 [00:28<00:25,  1.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  48%|####8     | 24/50 [00:29<00:19,  1.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  50%|#####     | 25/50 [00:31<00:29,  1.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  52%|#####2    | 26/50 [00:31<00:22,  1.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  54%|#####4    | 27/50 [00:32<00:17,  1.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  56%|#####6    | 28/50 [00:34<00:26,  1.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  58%|#####8    | 29/50 [00:34<00:19,  1.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  60%|######    | 30/50 [00:34<00:14,  1.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  62%|######2   | 31/50 [00:38<00:30,  1.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  64%|######4   | 32/50 [00:41<00:34,  1.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  66%|######6   | 33/50 [00:44<00:37,  2.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  68%|######8   | 34/50 [00:46<00:38,  2.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  70%|#######   | 35/50 [00:49<00:37,  2.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  72%|#######2  | 36/50 [00:52<00:36,  2.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  74%|#######4  | 37/50 [00:55<00:34,  2.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  76%|#######6  | 38/50 [00:58<00:33,  2.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  78%|#######8  | 39/50 [00:58<00:22,  2.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  80%|########  | 40/50 [00:59<00:15,  1.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  82%|########2 | 41/50 [01:01<00:15,  1.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  84%|########4 | 42/50 [01:01<00:10,  1.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  86%|########6 | 43/50 [01:01<00:07,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  88%|########8 | 44/50 [01:04<00:08,  1.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  90%|######### | 45/50 [01:04<00:05,  1.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  92%|#########2| 46/50 [01:04<00:03,  1.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  94%|#########3| 47/50 [01:05<00:02,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  96%|#########6| 48/50 [01:07<00:02,  1.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  98%|#########8| 49/50 [01:07<00:00,  1.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler: 100%|##########| 50/50 [01:07<00:00,  1.39it/s]\u001b[A\u001b[A\n",
      "DDIM Sampler: 100%|##########| 50/50 [01:07<00:00,  1.36s/it]\n",
      "\n",
      "\n",
      "data: 100%|##########| 1/1 [01:10<00:00, 70.26s/it]\u001b[A\n",
      "data: 100%|##########| 1/1 [01:10<00:00, 70.26s/it]\n",
      "\n",
      "Sampling:  50%|#####     | 2/4 [01:47<01:53, 56.76s/it]\n",
      "\n",
      "data:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:   2%|2         | 1/50 [00:00<00:14,  3.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:   4%|4         | 2/50 [00:00<00:13,  3.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:   6%|6         | 3/50 [00:02<00:54,  1.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:   8%|8         | 4/50 [00:03<00:38,  1.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  10%|#         | 5/50 [00:03<00:28,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  12%|#2        | 6/50 [00:03<00:22,  1.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  14%|#4        | 7/50 [00:05<00:47,  1.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  16%|#6        | 8/50 [00:06<00:35,  1.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  18%|#8        | 9/50 [00:06<00:27,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  20%|##        | 10/50 [00:08<00:46,  1.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  22%|##2       | 11/50 [00:09<00:35,  1.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  24%|##4       | 12/50 [00:09<00:27,  1.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  26%|##6       | 13/50 [00:12<00:47,  1.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  28%|##8       | 14/50 [00:14<01:00,  1.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  30%|###       | 15/50 [00:18<01:22,  2.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  32%|###2      | 16/50 [00:21<01:27,  2.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  34%|###4      | 17/50 [00:24<01:25,  2.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  36%|###6      | 18/50 [00:26<01:23,  2.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  38%|###8      | 19/50 [00:30<01:25,  2.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  40%|####      | 20/50 [00:32<01:24,  2.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  42%|####2     | 21/50 [00:35<01:18,  2.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  44%|####4     | 22/50 [00:38<01:19,  2.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  46%|####6     | 23/50 [00:42<01:21,  3.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  48%|####8     | 24/50 [00:44<01:15,  2.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  50%|#####     | 25/50 [00:47<01:15,  3.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  52%|#####2    | 26/50 [00:52<01:21,  3.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  54%|#####4    | 27/50 [00:54<01:11,  3.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  56%|#####6    | 28/50 [00:54<00:49,  2.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  58%|#####8    | 29/50 [00:55<00:35,  1.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  60%|######    | 30/50 [00:57<00:37,  1.87s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  62%|######2   | 31/50 [00:57<00:26,  1.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  64%|######4   | 32/50 [00:58<00:19,  1.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  66%|######6   | 33/50 [01:00<00:24,  1.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  68%|######8   | 34/50 [01:00<00:17,  1.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  70%|#######   | 35/50 [01:00<00:12,  1.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  72%|#######2  | 36/50 [01:03<00:18,  1.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  74%|#######4  | 37/50 [01:03<00:12,  1.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  76%|#######6  | 38/50 [01:03<00:09,  1.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  78%|#######8  | 39/50 [01:04<00:07,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  80%|########  | 40/50 [01:06<00:11,  1.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  82%|########2 | 41/50 [01:06<00:07,  1.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  84%|########4 | 42/50 [01:07<00:05,  1.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  86%|########6 | 43/50 [01:09<00:08,  1.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  88%|########8 | 44/50 [01:09<00:05,  1.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  90%|######### | 45/50 [01:09<00:03,  1.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  92%|#########2| 46/50 [01:12<00:04,  1.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  94%|#########3| 47/50 [01:12<00:02,  1.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  96%|#########6| 48/50 [01:12<00:01,  1.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  98%|#########8| 49/50 [01:14<00:01,  1.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler: 100%|##########| 50/50 [01:17<00:00,  1.51s/it]\u001b[A\u001b[A\n",
      "DDIM Sampler: 100%|##########| 50/50 [01:17<00:00,  1.55s/it]\n",
      "\n",
      "\n",
      "data: 100%|##########| 1/1 [01:18<00:00, 78.93s/it]\u001b[A\n",
      "data: 100%|##########| 1/1 [01:18<00:00, 78.93s/it]\n",
      "\n",
      "Sampling:  75%|#######5  | 3/4 [03:06<01:06, 66.88s/it]\n",
      "\n",
      "data:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:   2%|2         | 1/50 [00:05<04:35,  5.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:   4%|4         | 2/50 [00:05<01:59,  2.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:   6%|6         | 3/50 [00:06<01:10,  1.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:   8%|8         | 4/50 [00:08<01:22,  1.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  10%|#         | 5/50 [00:08<00:57,  1.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  12%|#2        | 6/50 [00:09<00:41,  1.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  14%|#4        | 7/50 [00:09<00:31,  1.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  16%|#6        | 8/50 [00:11<00:52,  1.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  18%|#8        | 9/50 [00:12<00:38,  1.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  20%|##        | 10/50 [00:12<00:29,  1.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  22%|##2       | 11/50 [00:14<00:47,  1.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  24%|##4       | 12/50 [00:14<00:35,  1.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  26%|##6       | 13/50 [00:15<00:27,  1.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  28%|##8       | 14/50 [00:17<00:44,  1.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  30%|###       | 15/50 [00:17<00:33,  1.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  32%|###2      | 16/50 [00:18<00:25,  1.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  34%|###4      | 17/50 [00:18<00:20,  1.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  36%|###6      | 18/50 [00:20<00:37,  1.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  38%|###8      | 19/50 [00:21<00:28,  1.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  40%|####      | 20/50 [00:21<00:21,  1.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  42%|####2     | 21/50 [00:23<00:34,  1.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  44%|####4     | 22/50 [00:24<00:25,  1.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  46%|####6     | 23/50 [00:24<00:19,  1.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  48%|####8     | 24/50 [00:27<00:36,  1.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  50%|#####     | 25/50 [00:29<00:43,  1.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  52%|#####2    | 26/50 [00:32<00:46,  1.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  54%|#####4    | 27/50 [00:32<00:33,  1.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  56%|#####6    | 28/50 [00:32<00:24,  1.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  58%|#####8    | 29/50 [00:35<00:31,  1.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  60%|######    | 30/50 [00:35<00:22,  1.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  62%|######2   | 31/50 [00:35<00:16,  1.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  64%|######4   | 32/50 [00:38<00:23,  1.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  66%|######6   | 33/50 [00:38<00:17,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  68%|######8   | 34/50 [00:38<00:12,  1.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  70%|#######   | 35/50 [00:39<00:09,  1.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  72%|#######2  | 36/50 [00:41<00:16,  1.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  74%|#######4  | 37/50 [00:41<00:11,  1.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  76%|#######6  | 38/50 [00:42<00:08,  1.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  78%|#######8  | 39/50 [00:44<00:13,  1.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  80%|########  | 40/50 [00:44<00:09,  1.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  82%|########2 | 41/50 [00:45<00:06,  1.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  84%|########4 | 42/50 [00:47<00:09,  1.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  86%|########6 | 43/50 [00:47<00:06,  1.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  88%|########8 | 44/50 [00:48<00:04,  1.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  90%|######### | 45/50 [00:50<00:06,  1.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  92%|#########2| 46/50 [00:50<00:03,  1.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  94%|#########3| 47/50 [00:51<00:02,  1.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  96%|#########6| 48/50 [00:53<00:02,  1.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler:  98%|#########8| 49/50 [00:53<00:00,  1.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "DDIM Sampler: 100%|##########| 50/50 [00:54<00:00,  1.29it/s]\u001b[A\u001b[A\n",
      "DDIM Sampler: 100%|##########| 50/50 [00:54<00:00,  1.08s/it]\n",
      "\n",
      "\n",
      "data: 100%|##########| 1/1 [00:54<00:00, 54.34s/it]\u001b[A\n",
      "data: 100%|##########| 1/1 [00:54<00:00, 54.34s/it]\n",
      "\n",
      "Sampling: 100%|##########| 4/4 [04:01<00:00, 61.93s/it]\n",
      "Sampling: 100%|##########| 4/4 [04:01<00:00, 60.25s/it]\n"
     ]
    }
   ],
   "source": [
    "file_name = \"2022-10-29T12-41-29_sciadi_24_training_images_2000_max_training_steps_sciadi_token_woman_class_word.ckpt\"\n",
    "\n",
    "!py scripts/stable_txt2img.py \\\n",
    " --ddim_eta 0.0 \\\n",
    " --n_samples 1 \\\n",
    " --n_iter 4 \\\n",
    " --scale 7.0 \\\n",
    " --ddim_steps 50 \\\n",
    " --ckpt \"./trained_models/{file_name}\" \\\n",
    " --prompt \"artwork of a pokmon trainer, sciadi woman, art by ken sugimori\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488b90fc-163c-46a0-bb42-114e7aef223a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
